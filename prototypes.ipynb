{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "423fe75d-9e19-4482-8511-9bd9c52c2e65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57e1452-8cc0-48e9-bb85-3ae9b2b93fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c66b6b-8840-4dc0-8cf5-9a91b34de09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gin/anaconda3/envs/env0/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73e2c5c-3b40-46f8-b9e4-65a8ad3db6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MetricCollection, AUROC, Recall, Precision, F1Score, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13af564-9520-422b-a10b-3f0e935c25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf3338e-f806-40cb-b7e3-c9e7bc29690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, TargetEncoder, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "# from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63dc3b4a-3f53-45bd-8fe7-33a269229633",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 13\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "PATH = './'\n",
    "EVAL_SIZE = 0.05\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d487b9-943e-42da-97f0-ec06fb3ae521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col='id')\n",
    "df_test = pd.read_csv('test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "011bde95-b99b-4351-bcb0-eada28abc5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>65101.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>58911.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>38043.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>31951.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  Age  Driving_License  Region_Code  Previously_Insured Vehicle_Age  \\\n",
       "id                                                                              \n",
       "0     Male   21                1         35.0                   0    1-2 Year   \n",
       "1     Male   43                1         28.0                   0   > 2 Years   \n",
       "2   Female   25                1         14.0                   1    < 1 Year   \n",
       "3   Female   35                1          1.0                   0    1-2 Year   \n",
       "4   Female   36                1         15.0                   1    1-2 Year   \n",
       "\n",
       "   Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  Response  \n",
       "id                                                                          \n",
       "0             Yes         65101.0                 124.0      187         0  \n",
       "1             Yes         58911.0                  26.0      288         1  \n",
       "2              No         38043.0                 152.0      254         0  \n",
       "3             Yes          2630.0                 156.0       76         0  \n",
       "4              No         31951.0                 152.0      294         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11504798 entries, 0 to 11504797\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   Gender                object \n",
      " 1   Age                   int64  \n",
      " 2   Driving_License       int64  \n",
      " 3   Region_Code           float64\n",
      " 4   Previously_Insured    int64  \n",
      " 5   Vehicle_Age           object \n",
      " 6   Vehicle_Damage        object \n",
      " 7   Annual_Premium        float64\n",
      " 8   Policy_Sales_Channel  float64\n",
      " 9   Vintage               int64  \n",
      " 10  Response              int64  \n",
      "dtypes: float64(3), int64(5), object(3)\n",
      "memory usage: 1.0+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.150480e+07</td>\n",
       "      <td>1.150480e+07</td>\n",
       "      <td>1.150480e+07</td>\n",
       "      <td>1.150480e+07</td>\n",
       "      <td>1.150480e+07</td>\n",
       "      <td>1.150480e+07</td>\n",
       "      <td>1.150480e+07</td>\n",
       "      <td>1.150480e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.838356e+01</td>\n",
       "      <td>9.980220e-01</td>\n",
       "      <td>2.641869e+01</td>\n",
       "      <td>4.629966e-01</td>\n",
       "      <td>3.046137e+04</td>\n",
       "      <td>1.124254e+02</td>\n",
       "      <td>1.638977e+02</td>\n",
       "      <td>1.229973e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.499346e+01</td>\n",
       "      <td>4.443120e-02</td>\n",
       "      <td>1.299159e+01</td>\n",
       "      <td>4.986289e-01</td>\n",
       "      <td>1.645475e+04</td>\n",
       "      <td>5.403571e+01</td>\n",
       "      <td>7.997953e+01</td>\n",
       "      <td>3.284341e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.630000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.527700e+04</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.182400e+04</td>\n",
       "      <td>1.510000e+02</td>\n",
       "      <td>1.660000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.945100e+04</td>\n",
       "      <td>1.520000e+02</td>\n",
       "      <td>2.320000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.500000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.401650e+05</td>\n",
       "      <td>1.630000e+02</td>\n",
       "      <td>2.990000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age  Driving_License   Region_Code  Previously_Insured  \\\n",
       "count  1.150480e+07     1.150480e+07  1.150480e+07        1.150480e+07   \n",
       "mean   3.838356e+01     9.980220e-01  2.641869e+01        4.629966e-01   \n",
       "std    1.499346e+01     4.443120e-02  1.299159e+01        4.986289e-01   \n",
       "min    2.000000e+01     0.000000e+00  0.000000e+00        0.000000e+00   \n",
       "25%    2.400000e+01     1.000000e+00  1.500000e+01        0.000000e+00   \n",
       "50%    3.600000e+01     1.000000e+00  2.800000e+01        0.000000e+00   \n",
       "75%    4.900000e+01     1.000000e+00  3.500000e+01        1.000000e+00   \n",
       "max    8.500000e+01     1.000000e+00  5.200000e+01        1.000000e+00   \n",
       "\n",
       "       Annual_Premium  Policy_Sales_Channel       Vintage      Response  \n",
       "count    1.150480e+07          1.150480e+07  1.150480e+07  1.150480e+07  \n",
       "mean     3.046137e+04          1.124254e+02  1.638977e+02  1.229973e-01  \n",
       "std      1.645475e+04          5.403571e+01  7.997953e+01  3.284341e-01  \n",
       "min      2.630000e+03          1.000000e+00  1.000000e+01  0.000000e+00  \n",
       "25%      2.527700e+04          2.900000e+01  9.900000e+01  0.000000e+00  \n",
       "50%      3.182400e+04          1.510000e+02  1.660000e+02  0.000000e+00  \n",
       "75%      3.945100e+04          1.520000e+02  2.320000e+02  0.000000e+00  \n",
       "max      5.401650e+05          1.630000e+02  2.990000e+02  1.000000e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "display(df_train.info())\n",
    "display(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68cbb38f-aab8-48f5-96c4-53b7f5d3e835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7669866 entries, 11504798 to 19174663\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   Gender                object \n",
      " 1   Age                   int64  \n",
      " 2   Driving_License       int64  \n",
      " 3   Region_Code           float64\n",
      " 4   Previously_Insured    int64  \n",
      " 5   Vehicle_Age           object \n",
      " 6   Vehicle_Damage        object \n",
      " 7   Annual_Premium        float64\n",
      " 8   Policy_Sales_Channel  float64\n",
      " 9   Vintage               int64  \n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 643.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b87f93-9b1c-4106-9884-6811ca8cf46b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4888cacb-3bd2-4780-ab50-0c11779eb123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.duplicated().sum())\n",
    "display(df_test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bd1441d-2488-4fdc-8cb9-cc301efb988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                  0\n",
       "Age                     0\n",
       "Driving_License         0\n",
       "Region_Code             0\n",
       "Previously_Insured      0\n",
       "Vehicle_Age             0\n",
       "Vehicle_Damage          0\n",
       "Annual_Premium          0\n",
       "Policy_Sales_Channel    0\n",
       "Vintage                 0\n",
       "Response                0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gender                  0\n",
       "Age                     0\n",
       "Driving_License         0\n",
       "Region_Code             0\n",
       "Previously_Insured      0\n",
       "Vehicle_Age             0\n",
       "Vehicle_Damage          0\n",
       "Annual_Premium          0\n",
       "Policy_Sales_Channel    0\n",
       "Vintage                 0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.isna().sum())\n",
    "display(df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbcc89df-fa0d-4630-b88c-e80f81d24ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "polsalchan_vc = df['Policy_Sales_Channel'].value_counts()\n",
    "sparce_polsalchan = polsalchan_vc[polsalchan_vc < 100].index.to_list()\n",
    "df.loc[df['Policy_Sales_Channel'].isin(sparce_polsalchan), 'Policy_Sales_Channel'] = -1\n",
    "\n",
    "df.loc[df['Region_Code']==39.2, 'Region_Code'] = 39.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "197f414a-c94c-4039-b104-3f9046a31340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['Policy_Sales_Channel'].isin(sparce_polsalchan), 'Policy_Sales_Channel'] = -1\n",
    "df_test.loc[df_test['Policy_Sales_Channel'].isin(sparce_polsalchan), 'Policy_Sales_Channel'] = -1\n",
    "\n",
    "df_train.loc[df_train['Region_Code']==39.2, 'Region_Code'] = 39.0\n",
    "df_test.loc[df_test['Region_Code']==39.2, 'Region_Code'] = 39.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1c30b8-060a-4395-a0fd-cce96058d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = ['Gender', 'Vehicle_Damage']\n",
    "cat_cols = ['Region_Code', 'Vehicle_Age', 'Policy_Sales_Channel', 'Vintage']\n",
    "num_cols = ['Age', 'Driving_License', 'Previously_Insured', 'Annual_Premium']\n",
    "target   = ['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9dbea7c-c595-41de-8aa9-ee31ccc63998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float32(x):\n",
    "    return(x.astype(np.float32))\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ColumnTransformer([('bin_encode',\n",
    "                        make_pipeline(OrdinalEncoder(),\n",
    "                                      # FunctionTransformer(lambda x: x.astype(np.float32)),\n",
    "                                      FunctionTransformer(func=to_float32),\n",
    "                                      StandardScaler()\n",
    "                                     ), bin_cols),\n",
    "\n",
    "                       ('num_encode',\n",
    "                        make_pipeline(StandardScaler(),\n",
    "                                      # FunctionTransformer(lambda x: x.astype(np.float32))\n",
    "                                      FunctionTransformer(func=to_float32),\n",
    "                                     ), num_cols),\n",
    "                      \n",
    "                       ('cat_encode',\n",
    "                       make_pipeline(OrdinalEncoder(),\n",
    "                                     # FunctionTransformer(lambda x: x.astype(np.int32))\n",
    "                                     FunctionTransformer(func=to_float32),\n",
    "                                    ), cat_cols)],\n",
    "                       \n",
    "                       remainder='drop')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c29bd9-c9ec-4719-9da1-6f0fdb65bce7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Embeddings training (Non-Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1f45ba-ae1e-4623-9b7c-00af86a9abe9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b0decb-e89a-4f98-813b-170db2f1ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosEmb_Dataset(Dataset):\n",
    "    def __init__(self, df, is_eval=False, is_test=False):\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.df.loc[:, target] = self.df.loc[:, target].where(self.df[target]==1, -1)\n",
    "        self.is_eval = is_eval\n",
    "        self.is_test = is_test\n",
    "        self.length = len(self.df)\n",
    "\n",
    "        if self.is_test:\n",
    "            self.X = self.df\n",
    "        else:\n",
    "            self.X, self.y = self.df.drop(target, axis=1), self.df[target].values\n",
    "        \n",
    "        if self.is_test or self.is_eval:\n",
    "            self.X = pipeline.transform(self.X)\n",
    "        else:\n",
    "            self.X = pipeline.fit_transform(self.X)\n",
    "        gc.collect()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        contr_index = random.randint(0, self.length-1) \n",
    "        # print(contr_index)\n",
    "        # if self.is_test: return self.X[index], None\n",
    "        return self.X[index], self.X[contr_index], self.y[index]*self.y[contr_index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ffaf76-41b4-4cf1-b3fa-3ae26f1e078a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### CosEmb Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef5a08d8-73c2-4377-a00c-f302f015ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosEmb(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int = 6+8+2+12+18,\n",
    "                 emb_szs = [(53, 8), (3, 2), (123, 12), (290, 18)],\n",
    "                 add_num = False,\n",
    "                 use_fc = False\n",
    "                ):\n",
    "        super(CosEmb, self).__init__()\n",
    "    \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(in_sz, out_sz) for in_sz, out_sz in emb_szs])\n",
    "        self.add_num = add_num\n",
    "        self.use_fc = use_fc\n",
    "        if not add_num: input_dim = sum([i[1] for i in emb_szs])\n",
    "        self.fc = nn.Sequential(\n",
    "                                nn.Linear(input_dim, 256),\n",
    "                                nn.LazyBatchNorm1d(256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(256, 256),\n",
    "                                # nn.LazyBatchNorm1d(256),\n",
    "                                # nn.ReLU(),\n",
    "                                # nn.Linear(256, 256)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1_num = x1[:, :6]\n",
    "        x1_cat = x1[:, 6:].long()\n",
    "        x1_cat = [emb_layer(x1_cat[:, i]) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        x1_cat = torch.cat(x1_cat, dim=-1)\n",
    "        \n",
    "        x2_num = x2[:, :6]\n",
    "        x2_cat = x2[:, 6:].long()\n",
    "        x2_cat = [emb_layer(x2_cat[:, i]) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        x2_cat = torch.cat(x2_cat, dim=-1)\n",
    "\n",
    "        if self.add_num:\n",
    "            x1 = torch.cat([x1_num, x1_cat], dim=-1).float()\n",
    "            x2 = torch.cat([x2_num, x2_cat], dim=-1).float()\n",
    "        else:\n",
    "            x1 = x1_cat.float()\n",
    "            x2 = x2_cat.float()\n",
    "\n",
    "        if self.use_fc:\n",
    "            x1 = self.fc(x1)\n",
    "            x2 = self.fc(x2)\n",
    "        \n",
    "        return x1, x2\n",
    "\n",
    "    def make_embs(self, x):\n",
    "        x_num = x[:, :6]\n",
    "        x_cat = x[:, 6:].long()\n",
    "        x_cat = [emb_layer(x_cat[:, i]) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        x_cat = torch.cat(x_cat, dim=-1)\n",
    "        \n",
    "        if self.add_num:\n",
    "            x = torch.cat([x_num, x_cat], dim=-1).float()\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8fc22b6-c91d-4d9c-9bb8-9049fbbe4a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_cosemb(model, optimizer, loss_fn, train_dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for X1, X2, y in tqdm.tqdm(train_dataloader):\n",
    "        X1, X2, y = X1.to(DEVICE), X2.to(DEVICE), y.to(DEVICE).squeeze_()\n",
    "\n",
    "        preds1, preds2 = model(X1, X2)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(preds1, preds2, y.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(train_dataloader)\n",
    "    \n",
    "def evaluate_cosemb(model, loss_fn, test_dataloader, altmetric=None):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for X1, X2, y in test_dataloader:\n",
    "        X1, X2, y = X1.to(DEVICE), X2.to(DEVICE), y.to(DEVICE).squeeze_()\n",
    "        \n",
    "        preds1, preds2 = model(X1, X2)\n",
    "        loss = loss_fn(preds1, preds2, y.float())\n",
    "\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dda02f-fb0c-40e4-ac9f-e2d200a9a165",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### CosEmb Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a4fa47-8498-4510-9f62-c1f315a4a5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_train_train, df_train_eval = train_test_split(df_train, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                                  shuffle=True, stratify=df_train[target])\n",
    "\n",
    "# dataset_train = CosEmb_Dataset(df_train_train)\n",
    "# dataset_eval = CosEmb_Dataset(df_train_eval, is_eval=True)\n",
    "# # dataset_train = Base_Dataset(df_train)\n",
    "\n",
    "# display(len(dataset_train))\n",
    "# display(len(dataset_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84dee839-8d38-4b5d-bb7a-c8aa1dc2864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# EMB_0, EMB_1, EMB_2, EMB_3 = 25, 2, 50, 50\n",
    "# # EMB_0, EMB_1, EMB_2, EMB_3 = 15, 2, 25, 25\n",
    "# INPUT_DIM = 6+EMB_0+EMB_1+EMB_2+EMB_3\n",
    "# EMB_SZS = [(53, EMB_0), (3, EMB_1), (123, EMB_2), (290, EMB_3)]\n",
    "# ADD_NUM = True\n",
    "# USE_FC = True\n",
    "\n",
    "# NUM_EPOCHS = 128\n",
    "# BATCH_SIZE = 1024*4\n",
    "# LR = 0.001 #0.001\n",
    "# WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# cosemb = CosEmb(input_dim=INPUT_DIM,\n",
    "#               emb_szs=EMB_SZS,\n",
    "#               add_num=ADD_NUM,\n",
    "#               use_fc=USE_FC\n",
    "#               )\n",
    "\n",
    "\n",
    "# cosemb.to(DEVICE)\n",
    "\n",
    "# sampler_weights = torch.Tensor(np.where(df_train_train['Response']==0, 1, 8))\n",
    "# num_samples = len(df_train_train)\n",
    "# sampler = torch.utils.data.WeightedRandomSampler(num_samples=num_samples, weights=sampler_weights)\n",
    "# trainloader = torch.utils.data.DataLoader(dataset_train, sampler=sampler,\n",
    "#                                           batch_size=BATCH_SIZE, shuffle=False,\n",
    "#                                           num_workers=8, drop_last=False)\n",
    "\n",
    "# evalloader = torch.utils.data.DataLoader(dataset_eval,\n",
    "#                                          batch_size=BATCH_SIZE, shuffle=True,\n",
    "#                                          num_workers=8, drop_last=False)\n",
    "\n",
    "# loss_fn = nn.CosineEmbeddingLoss()\n",
    "# optimizer = torch.optim.AdamW(cosemb.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9937534-2f44-404e-9d9b-64334b88a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     train_loss = train_epoch_cosemb(cosemb, optimizer, loss_fn, trainloader)\n",
    "#     eval_loss = evaluate_cosemb(cosemb, loss_fn, evalloader)\n",
    "#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.5f}, Val loss: {eval_loss:.5f}\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee9ea131-2a4e-4501-a646-9da6e936471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(cosemb.embeddings[2].weight.cpu().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a83f8d3d-1f8e-4008-829e-added60578ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(cosemb.embeddings[1].weight.cpu().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3079d959-6116-475d-9e21-4188a43a80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PATH+'pipeline', 'wb') as fp:\n",
    "#     pickle.dump(pipeline, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce6ee43-ce02-4883-8bf4-8c44fccfc106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PATH+'embeddings_cosemb-wnum-128.pth', 'wb') as fp:\n",
    "#     pickle.dump(cosemb.embeddings, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f918370-c1e4-4d36-ab95-7c6f48edc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PATH+'cosemb256-wnum-128.pth', 'wb') as fp:\n",
    "#     torch.save(cosemb, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3e6ea-d249-43d4-abab-5961abb30db9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### CosEmb optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4de7e24-02bc-47e4-87cd-5c19ec9b4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_train, df_train_eval = train_test_split(df_train, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                                  shuffle=True, stratify=df_train[target])\n",
    "\n",
    "# dataset_train = CosEmb_Dataset(df_train_train)\n",
    "# dataset_eval = CosEmb_Dataset(df_train_eval, is_eval=True)\n",
    "# # dataset_train = Base_Dataset(df_train)\n",
    "\n",
    "# display(len(dataset_train))\n",
    "# display(len(dataset_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2d5d348-5408-424c-abef-be99044e8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # model's params\n",
    "    EMB_0, EMB_1, EMB_2, EMB_3 = 25, 2, 50, 50\n",
    "    # EMB_0, EMB_1, EMB_2, EMB_3 = trial.suggest_int('EMB_0', 7, 15, step=1),\\\n",
    "    #                              trial.suggest_int('EMB_1', 2, 3, step=1),\\\n",
    "    #                              trial.suggest_int('EMB_2', 23, 27, step=1),\\\n",
    "    #                              trial.suggest_int('EMB_3', 17, 23, step=1)\n",
    "    INPUT_DIM = 6+EMB_0+EMB_1+EMB_2+EMB_3\n",
    "    EMB_SZS = [(53, EMB_0), (3, EMB_1), (123, EMB_2), (290, EMB_3)]\n",
    "    \n",
    "    # learning params\n",
    "    NUM_EPOCHS = trial.suggest_int('NUM_EPOCHS', 16, 64, step=8)\n",
    "    BATCH_SIZE = 1024*4 #trial.suggest_int('BATCH_SIZE', 2048, 8192, step=2048) #2048\n",
    "    LR = trial.suggest_float('LR', 1e-5, 1e-2, log=True)\n",
    "    WEIGHT_DECAY = trial.suggest_float('WEIGHT_DECAY', 1e-6, 1e-3, log=True)\n",
    "    \n",
    "    cosemb = CosEmb(input_dim=INPUT_DIM,\n",
    "                  emb_szs=EMB_SZS,\n",
    "                  add_num=False\n",
    "                  )\n",
    "    cosemb.to(DEVICE)\n",
    "    \n",
    "    sampler_weights = torch.Tensor(np.where(df_train_train['Response']==0, 1, 8))\n",
    "    num_samples = len(df_train_train)\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(num_samples=num_samples, weights=sampler_weights)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset_train, sampler=sampler,\n",
    "                                              batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                              num_workers=8, drop_last=False)\n",
    "    \n",
    "    evalloader = torch.utils.data.DataLoader(dataset_eval,\n",
    "                                             batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                             num_workers=8, drop_last=False)\n",
    "    \n",
    "    loss_fn = nn.CosineEmbeddingLoss()\n",
    "    optimizer = torch.optim.AdamW(cosemb.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        train_loss = train_epoch_cosemb(cosemb, optimizer, loss_fn, trainloader)\n",
    "        \n",
    "        if ((epoch)%4==0):\n",
    "            eval_loss = evaluate_cosemb(cosemb, loss_fn, evalloader)\n",
    "            trial.report(eval_loss, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    eval_loss = evaluate_cosemb(cosemb, loss_fn, evalloader)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cb90ce4-eba9-4dd2-8324-ed4296016d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "# # storage = optuna.storages.InMemoryStorage()\n",
    "\n",
    "# study = optuna.create_study(direction='minimize', sampler=sampler,\n",
    "#                             study_name='cosemb-study_cosdist', storage='sqlite:///cosemb-study_cosdist.db', load_if_exists=True,\n",
    "#                             pruner=optuna.pruners.MedianPruner(n_startup_trials=16,\n",
    "#                                                                n_warmup_steps=16)\n",
    "#                            )\n",
    "# study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad2a61-44a3-4b7c-9ffd-8a18ed16e26a",
   "metadata": {},
   "source": [
    "### Embeddings training (Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabef43-7c72-4379-b1dc-51b3a37587a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94c32265-142b-479a-852d-5337bc70df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Dataset(Dataset):\n",
    "    def __init__(self, df, is_eval=False, is_test=False):\n",
    "        \n",
    "        self.df = df\n",
    "        self.is_eval = is_eval\n",
    "        self.is_test = is_test\n",
    "\n",
    "        if self.is_test:\n",
    "            self.X = self.df\n",
    "        else:\n",
    "            self.X, self.y = self.df.drop(target, axis=1), self.df[target].values\n",
    "        \n",
    "        if self.is_test or self.is_eval:\n",
    "            self.X = pipeline.transform(self.X)\n",
    "        else:\n",
    "            self.X = pipeline.fit_transform(self.X)\n",
    "        gc.collect()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # if self.is_test: return self.X[index], None\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626571db-eb8f-4c94-bfa9-679c30ec072f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### FCNNet Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d20b1e5-ba08-4aad-816c-256502d1ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int = 6+8+2+12+18,\n",
    "                 layers_num: int = 2,\n",
    "                 layers_dim: int = 32,\n",
    "                 activation = nn.ReLU,\n",
    "                 emb_szs = [(53, 8), (3, 2), (123, 12), (290, 18)],\n",
    "                 dropout: float = 0.,\n",
    "                ):\n",
    "        super(FCNNet, self).__init__()\n",
    "    \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(in_sz, out_sz) for in_sz, out_sz in emb_szs])\n",
    "    \n",
    "        fc_layers = []\n",
    "        fc_layers.append(nn.Linear(input_dim, layers_dim))\n",
    "        fc_layers.append(nn.LazyBatchNorm1d())\n",
    "        fc_layers.append(activation())\n",
    "        fc_layers.append(nn.Dropout(p=dropout))\n",
    "        for i in range(layers_num):\n",
    "            fc_layers.append(nn.Linear(layers_dim, layers_dim))\n",
    "            fc_layers.append(nn.LazyBatchNorm1d())\n",
    "            fc_layers.append(activation())\n",
    "            fc_layers.append(nn.Dropout(p=dropout))\n",
    "        fc_layers.append(nn.Linear(layers_dim, 1))\n",
    "    \n",
    "        self.fc_layers = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_num = x[:, :6]\n",
    "        x_cat = x[:, 6:].long()\n",
    "        x_cat = [emb_layer(x_cat[:, i]) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        x_cat = torch.cat(x_cat, dim=-1)\n",
    "\n",
    "        x = torch.cat([x_num, x_cat], dim=-1).float()\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97f4cafd-fd5b-442d-bdca-9b333f608586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_fcnn(model, optimizer, loss_fn, train_dataloader, altmetric=None):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for X, y in tqdm.tqdm(train_dataloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        preds = model(X)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(preds, y.float())\n",
    "        if altmetric: altmetric.update(preds,y.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(train_dataloader)\n",
    "    \n",
    "def evaluate_fcnn(model, loss_fn, test_dataloader, altmetric=None):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        \n",
    "        preds = model(X)\n",
    "        loss = loss_fn(preds, y.float())\n",
    "        if altmetric: altmetric.update(preds,y.float())\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf9899-bff2-4517-9b79-a4690dd6170b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### FCNNet Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb5fb1be-0e8b-4ac2-b89e-14d947d37cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosemb = torch.load('cosemb256-wnum-128.pth')\n",
    "\n",
    "# with open(PATH+'pipeline', 'rb') as fp:\n",
    "#     pipeline = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bbc32d0-6dea-44f1-941e-8f95f9901f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10929558"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "575240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_train_train, df_train_eval = train_test_split(df_train, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                                  shuffle=True, stratify=df_train[target])\n",
    "\n",
    "# dataset_train = Base_Dataset(df_train_train, is_eval=True)\n",
    "# dataset_eval = Base_Dataset(df_train_eval, is_eval=True)\n",
    "# # dataset_train = Base_Dataset(df_train)\n",
    "\n",
    "# display(len(dataset_train))\n",
    "# display(len(dataset_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c6af2e0-6aad-426a-bd31-14014213c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gin/anaconda3/envs/env0/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# EMB_0, EMB_1, EMB_2, EMB_3 = 25, 2, 50, 50\n",
    "# INPUT_DIM = 6+EMB_0+EMB_1+EMB_2+EMB_3\n",
    "# LAYERS_NUM = 2\n",
    "# LAYERS_DIM = 192\n",
    "# ACTIVATION = nn.ReLU\n",
    "# EMB_SZS = [(53, EMB_0), (3, EMB_1), (123, EMB_2), (290, EMB_3)]\n",
    "# DROPOUT = 0.1\n",
    "\n",
    "# NUM_EPOCHS = 8\n",
    "# BATCH_SIZE = 1024*4\n",
    "# LR = 0.0002 #0.001\n",
    "# WEIGHT_DECAY = 3e-4\n",
    "\n",
    "# fcnn = FCNNet(input_dim=INPUT_DIM,\n",
    "#               layers_num=LAYERS_NUM,\n",
    "#               layers_dim=LAYERS_DIM,\n",
    "#               activation=ACTIVATION,\n",
    "#               emb_szs=EMB_SZS,\n",
    "#               dropout=DROPOUT\n",
    "#               )\n",
    "\n",
    "# altmetric_train = MetricCollection([AUROC(task='binary'),\n",
    "#                                     Recall(task='binary'),\n",
    "#                                     Precision(task='binary'),\n",
    "#                                     F1Score(task='binary'),\n",
    "#                                     Accuracy(task='binary')\n",
    "#                                    ])\n",
    "# altmetric_eval = MetricCollection([AUROC(task='binary'),\n",
    "#                                    Recall(task='binary'),\n",
    "#                                    Precision(task='binary'),\n",
    "#                                    F1Score(task='binary'),\n",
    "#                                    Accuracy(task='binary')\n",
    "#                                   ])\n",
    "\n",
    "# fcnn.to(DEVICE)\n",
    "# altmetric_train.to(DEVICE)\n",
    "# altmetric_eval.to(DEVICE)\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(dataset_train,\n",
    "#                                           batch_size=BATCH_SIZE, shuffle=True,\n",
    "#                                           num_workers=8, drop_last=False)\n",
    "# evalloader = torch.utils.data.DataLoader(dataset_eval,\n",
    "#                                          batch_size=BATCH_SIZE, shuffle=True,\n",
    "#                                          num_workers=8, drop_last=False)\n",
    "\n",
    "# loss_fn = nn.BCEWithLogitsLoss(\n",
    "#                                # weight=torch.Tensor([8]).to(DEVICE),\n",
    "#                                # pos_weight=torch.Tensor([8]).to(DEVICE)\n",
    "#                               )\n",
    "# optimizer = torch.optim.AdamW(fcnn.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "873af87c-d19e-4b40-9e7d-44dd53d1f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcnn.embeddings = cosemb.embeddings\n",
    "# for p in fcnn.embeddings.parameters():\n",
    "#     p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82a66887-78bb-44db-bfb9-9ff8971fa7c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:21<00:00, 124.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.34209, Val loss: 0.26878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 117.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.26567, Val loss: 0.25878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 120.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.25962, Val loss: 0.25611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 116.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.25754, Val loss: 0.25511\n",
      "Train\n",
      "('BinaryAUROC', 0.87184)\n",
      "('BinaryRecall', 0.0816)\n",
      "('BinaryPrecision', 0.54992)\n",
      "('BinaryF1Score', 0.14211)\n",
      "('BinaryAccuracy', 0.87882)\n",
      "\n",
      "Test\n",
      "('BinaryAUROC', 0.87517)\n",
      "('BinaryRecall', 0.11823)\n",
      "('BinaryPrecision', 0.541)\n",
      "('BinaryF1Score', 0.19405)\n",
      "('BinaryAccuracy', 0.87921)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 120.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.25650, Val loss: 0.25454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:21<00:00, 125.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.25590, Val loss: 0.25439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 119.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 0.25545, Val loss: 0.25402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 116.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 0.25509, Val loss: 0.25372\n",
      "Train\n",
      "('BinaryAUROC', 0.87495)\n",
      "('BinaryRecall', 0.09721)\n",
      "('BinaryPrecision', 0.55691)\n",
      "('BinaryF1Score', 0.16553)\n",
      "('BinaryAccuracy', 0.87945)\n",
      "\n",
      "Test\n",
      "('BinaryAUROC', 0.87683)\n",
      "('BinaryRecall', 0.1211)\n",
      "('BinaryPrecision', 0.54895)\n",
      "('BinaryF1Score', 0.19842)\n",
      "('BinaryAccuracy', 0.87966)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 118.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 0.25477, Val loss: 0.25360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:23<00:00, 114.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.25456, Val loss: 0.25336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 119.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.25432, Val loss: 0.25310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:23<00:00, 115.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 0.25415, Val loss: 0.25308\n",
      "Train\n",
      "('BinaryAUROC', 0.87625)\n",
      "('BinaryRecall', 0.10585)\n",
      "('BinaryPrecision', 0.55774)\n",
      "('BinaryF1Score', 0.17793)\n",
      "('BinaryAccuracy', 0.8797)\n",
      "\n",
      "Test\n",
      "('BinaryAUROC', 0.87769)\n",
      "('BinaryRecall', 0.13228)\n",
      "('BinaryPrecision', 0.54808)\n",
      "('BinaryF1Score', 0.21312)\n",
      "('BinaryAccuracy', 0.87986)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:23<00:00, 113.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 0.25401, Val loss: 0.25301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:22<00:00, 120.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 0.25385, Val loss: 0.25286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1514/2669 [00:12<00:09, 125.88it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# PRINT_EVERY = 4\n",
    "\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     train_loss = train_epoch_fcnn(fcnn, optimizer, loss_fn, trainloader, altmetric=altmetric_train)\n",
    "#     eval_loss = evaluate_fcnn(fcnn, loss_fn, evalloader, altmetric=altmetric_eval)\n",
    "#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.5f}, Val loss: {eval_loss:.5f}\"))\n",
    "\n",
    "#     if ((epoch)%PRINT_EVERY==0):\n",
    "#         print('Train')\n",
    "#         for j in [(i, round(altmetric_train[i].compute().item(), 5))\n",
    "#                   for i in altmetric_train.keys()]: print(j)\n",
    "#         print()\n",
    "#         print('Test')\n",
    "#         for j in [(i, round(altmetric_eval[i].compute().item(), 5))\n",
    "#                   for i in altmetric_eval.keys()]: print(j)\n",
    "#         print()\n",
    "\n",
    "#     altmetric_train.reset()\n",
    "#     altmetric_eval.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6491063-ed24-4988-bb6f-58c32b167f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PATH+'pipeline', 'wb') as fp:\n",
    "#     pickle.dump(pipeline, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83042e1c-2df3-40bc-ab4d-1c5a331e626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PATH+'embeddings', 'wb') as fp:\n",
    "#     pickle.dump(fcnn.embeddings, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92833c8d-d60a-4bdc-9316-0b840da69fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "821a6e92-0d39-4506-bf79-7dcd41a80ad0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### FCNNet optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a533fe02-769a-4d14-944f-7ef5adf05eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_train, df_train_eval = train_test_split(df_train, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                                  shuffle=True, stratify=df_train[target])\n",
    "\n",
    "# dataset_train = Base_Dataset(df_train_train)\n",
    "# dataset_eval = Base_Dataset(df_train_eval, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1757a556-8624-4d7c-a7bb-222367ee447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATIONS = {'ReLU': nn.ReLU,\n",
    "               'SELU': nn.SELU,\n",
    "               'GELU': nn.GELU,\n",
    "               'RReLU': nn.RReLU,\n",
    "               'SiLU': nn.SiLU,\n",
    "               'LeakyReLU': nn.LeakyReLU,\n",
    "               'IDENTITY': nn.Identity,\n",
    "              }\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # model's params\n",
    "    EMB_0, EMB_1, EMB_2, EMB_3 = trial.suggest_int('EMB_0', 7, 15, step=1),\\\n",
    "                                 trial.suggest_int('EMB_1', 2, 3, step=1),\\\n",
    "                                 trial.suggest_int('EMB_2', 23, 27, step=1),\\\n",
    "                                 trial.suggest_int('EMB_3', 17, 23, step=1)\n",
    "    INPUT_DIM = 6+EMB_0+EMB_1+EMB_2+EMB_3\n",
    "    LAYERS_NUM = 0 #trial.suggest_int('LAYERS_NUM', 0, 4, step=1) #4\n",
    "    LAYERS_DIM = 192 #trial.suggest_int('LAYERS_DIM', 128, 384, step=64) #64\n",
    "    ACTIVATION_OPTIONS = 'ReLU' #trial.suggest_categorical('ACTIVATION', ['ReLU', 'SELU', 'GELU', 'RReLU'])\n",
    "    ACTIVATION = ACTIVATIONS[ACTIVATION_OPTIONS]\n",
    "    EMB_SZS = [(53, EMB_0), (3, EMB_1), (123, EMB_2), (290, EMB_3)]\n",
    "    DROPOUT = 0.15 #trial.suggest_float('DROPOUT', 0, 0.2)\n",
    "    \n",
    "    # learning params\n",
    "    NUM_EPOCHS = trial.suggest_int('NUM_EPOCHS', 16, 64, step=8)\n",
    "    BATCH_SIZE = 6144 #trial.suggest_int('BATCH_SIZE', 2048, 8192, step=2048) #2048\n",
    "    LR = trial.suggest_float('LR', 7e-4, 3e-3, log=True)\n",
    "    WEIGHT_DECAY = trial.suggest_float('WEIGHT_DECAY', 1e-4, 1e-3, log=True)\n",
    "    # POS_WEIGHT = trial.suggest_float('POS_WEIGHT', 1/4, 8, log=True)\n",
    "    \n",
    "    fcnn = FCNNet(input_dim=INPUT_DIM,\n",
    "                  layers_num=LAYERS_NUM,\n",
    "                  layers_dim=LAYERS_DIM,\n",
    "                  activation=ACTIVATION,\n",
    "                  emb_szs=EMB_SZS,\n",
    "                  dropout=DROPOUT\n",
    "                  )\n",
    "    # altmetric_train = MetricCollection([AUROC(task='binary'),\n",
    "    #                                     # Recall(task='binary'),\n",
    "    #                                     # Precision(task='binary'),\n",
    "    #                                     # F1Score(task='binary'),\n",
    "    #                                     # Accuracy(task='binary')\n",
    "    #                                    ])\n",
    "    altmetric_eval = MetricCollection([AUROC(task='binary'),\n",
    "                                       # Recall(task='binary'),\n",
    "                                       # Precision(task='binary'),\n",
    "                                       # F1Score(task='binary'),\n",
    "                                       # Accuracy(task='binary')\n",
    "                                      ])\n",
    "    \n",
    "    fcnn.to(DEVICE)\n",
    "    # altmetric_train.to(DEVICE)\n",
    "    altmetric_eval.to(DEVICE)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                              batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                              num_workers=8, drop_last=False)\n",
    "    evalloader = torch.utils.data.DataLoader(dataset_eval,\n",
    "                                             batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                             num_workers=8, drop_last=False)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss(\n",
    "        # pos_weight=torch.Tensor([POS_WEIGHT]).to(DEVICE)\n",
    "    )\n",
    "    optimizer = torch.optim.AdamW(fcnn.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        train_loss = train_epoch_fcnn(fcnn, optimizer, loss_fn, trainloader)\n",
    "        \n",
    "        if ((epoch)%4==0):\n",
    "            eval_loss = evaluate_fcnn(fcnn, loss_fn, evalloader, altmetric=altmetric_eval)\n",
    "            intermid_value = altmetric_eval['BinaryAUROC'].compute().item()\n",
    "            # trial.report(eval_loss, epoch)\n",
    "            trial.report(intermid_value, epoch)\n",
    "            altmetric_eval.reset()\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    eval_loss = evaluate_fcnn(fcnn, loss_fn, evalloader, altmetric=altmetric_eval)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    # return eval_loss\n",
    "    return altmetric_eval['BinaryAUROC'].compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c5e48a7-38d0-49c8-9645-e4345fcd954b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "# # storage = optuna.storages.InMemoryStorage()\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler=sampler,\n",
    "#                             study_name='fcnn-study_auc3', storage='sqlite:///fcnn-study_bce.db', load_if_exists=True,\n",
    "#                             pruner=optuna.pruners.MedianPruner(n_startup_trials=16,\n",
    "#                                                                n_warmup_steps=16)\n",
    "#                            )\n",
    "# study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c67ff-466e-4870-8dd7-b58fc1245ee7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DAE training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a2dfd-08e1-43ba-909e-416f5381c5a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DAE Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cf600f8-e6f9-477f-b53c-a0482b528966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int = 6+8+2+12+18,\n",
    "                 layers_num: int = 3,\n",
    "                 layers_dim: int = 64,\n",
    "                 activation = nn.ReLU,\n",
    "                 emb_szs = [(53, 8), (3, 2), (123, 12), (290, 18)],\n",
    "                 emb_weights = False,\n",
    "                 dropout: float = 0.,\n",
    "                 swapnoise_ratio = 0.15,\n",
    "                 return_obfuscation_mask = False,\n",
    "                ):\n",
    "        super(DAE, self).__init__()\n",
    "    \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(in_sz, out_sz) for in_sz, out_sz in emb_szs])\n",
    "        if (emb_weights==True):\n",
    "            for i, emb in enumerate(embeddings):\n",
    "                emb.weight = emb_weights[0].weight\n",
    "                for p in emb.parameters():\n",
    "                    p.requires_grad = False\n",
    "        self.swapnoise_ratio = swapnoise_ratio\n",
    "        self.return_obfuscation_mask = return_obfuscation_mask\n",
    "    \n",
    "        dae_layers = []\n",
    "        dae_layers.append(nn.Linear(input_dim, layers_dim))\n",
    "        dae_layers.append(activation())\n",
    "        dae_layers.append(nn.Dropout(p=dropout))\n",
    "        for i in range(layers_num):\n",
    "            dae_layers.append(nn.Linear(layers_dim, layers_dim))\n",
    "            dae_layers.append(activation())\n",
    "            dae_layers.append(nn.Dropout(p=dropout))\n",
    "        dae_layers.append(nn.Linear(layers_dim, input_dim))\n",
    "    \n",
    "        self.dae = nn.Sequential(*dae_layers)\n",
    "\n",
    "        ###########################\n",
    "        # distinctions for make_denoise\n",
    "        self.dae_layers = []\n",
    "        self.dae_layers.append([list(self.dae.children())[0]])\n",
    "        for i in range(1, len(self.dae)-3, 3):\n",
    "            self.dae_layers.append(list(self.dae.children())[:i+2+1])\n",
    "        self.dae_layers = [nn.Sequential(*i) for i in self.dae_layers]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_num = x[:, :6]\n",
    "        x_cat = x[:, 6:].long()\n",
    "        x_cat = [emb_layer(x_cat[:, i]) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        x_cat = torch.cat(x_cat, dim=-1)\n",
    "\n",
    "        x = torch.cat([x_num, x_cat], dim=-1).float()\n",
    "        x_orig = x.clone().detach() # for backforwarding\n",
    "        x, _ = self.add_swapnoise(x, ratio=self.swapnoise_ratio)\n",
    "        x = self.dae(x)\n",
    "\n",
    "        if (self.return_obfuscation_mask==True): return x, x_orig, _\n",
    "        return x, x_orig, None\n",
    "\n",
    "    def make_denoise(self, x: torch.Tensor):\n",
    "        if len(x.shape) == 1: x = x.unsqueeze(0)\n",
    "        x_num = x[:, :6]\n",
    "        x_cat = x[:, 6:].long()\n",
    "        x_cat = [emb_layer(x_cat[:, i]) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        x_cat = torch.cat(x_cat, dim=-1)\n",
    "        x = torch.cat([x_num, x_cat], dim=-1).float()\n",
    "        return torch.cat([i(x) for i in self.dae_layers][1:], dim=-1) #dropping first output\n",
    "\n",
    "    # https://www.kaggle.com/code/ryanzhang/pytorch-dae-starter-code\n",
    "    def add_swapnoise(self, x, ratio=0.15):\n",
    "        obfuscation_mask = torch.bernoulli(ratio * torch.ones(x.shape)).to(DEVICE)\n",
    "        obfuscated_x = torch.where(obfuscation_mask == 1, x[torch.randperm(x.shape[0])], x)\n",
    "        return obfuscated_x, obfuscation_mask\n",
    "\n",
    "class BottleDAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int = 6+8+2+12+18,\n",
    "                 layers_num: int = 2,\n",
    "                 layers_dim: int = 1024,\n",
    "                 gist_dim: int = 128,\n",
    "                 activation = nn.ReLU,\n",
    "                 emb_szs = [(53, 8), (3, 2), (123, 12), (290, 18)],\n",
    "                 emb_weights = False,\n",
    "                 dropout: float = 0.,\n",
    "                 swapnoise_ratio = 0.15,\n",
    "                 return_obfuscation_mask = False,\n",
    "                ):\n",
    "        super(BottleDAE, self).__init__()\n",
    "    \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(in_sz, out_sz) for in_sz, out_sz in emb_szs])\n",
    "        if (emb_weights==True):\n",
    "            for i, emb in enumerate(embeddings):\n",
    "                emb.weight = emb_weights[0].weight\n",
    "                for p in emb.parameters():\n",
    "                    p.requires_grad = False\n",
    "        self.swapnoise_ratio = swapnoise_ratio\n",
    "        self.return_obfuscation_mask = return_obfuscation_mask\n",
    "    \n",
    "        dae_layers = []\n",
    "        dae_layers.append(nn.Linear(input_dim, layers_dim))\n",
    "        dae_layers.append(activation())\n",
    "        dae_layers.append(nn.Dropout(p=dropout))\n",
    "        for i in range(layers_num-1):\n",
    "            dae_layers.append(nn.Linear(layers_dim, layers_dim))\n",
    "            dae_layers.append(activation())\n",
    "            dae_layers.append(nn.Dropout(p=dropout))\n",
    "        dae_layers.append(nn.Linear(layers_dim, gist_dim))\n",
    "        dae_layers.append(activation())\n",
    "        dae_layers.append(nn.Dropout(p=dropout))\n",
    "        dae_layers.append(nn.Linear(gist_dim, layers_dim))\n",
    "        dae_layers.append(activation())\n",
    "        dae_layers.append(nn.Dropout(p=dropout))\n",
    "        for i in range(layers_num-1):\n",
    "            dae_layers.append(nn.Linear(layers_dim, layers_dim))\n",
    "            dae_layers.append(activation())\n",
    "            dae_layers.append(nn.Dropout(p=dropout))\n",
    "        dae_layers.append(nn.Linear(layers_dim, input_dim))\n",
    "\n",
    "        self.dae = nn.Sequential(*dae_layers)\n",
    "\n",
    "        ###########################\n",
    "        # distinctions for make_denoise\n",
    "        self.dae_layers = nn.Sequential(*list(self.dae.children())[:3+(layers_num-1)*3+1])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_num = x[:, :6]\n",
    "        x_cat = x[:, 6:].long()\n",
    "        x_cat = [emb_layer(x_cat[:, i]) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        x_cat = torch.cat(x_cat, dim=-1)\n",
    "\n",
    "        x = torch.cat([x_num, x_cat], dim=-1).float()\n",
    "        x_orig = x.clone().detach() # for backforwarding\n",
    "        x, _ = self.add_swapnoise(x, ratio=self.swapnoise_ratio)\n",
    "        x = self.dae(x)\n",
    "\n",
    "        if (self.return_obfuscation_mask==True): return x, x_orig, _\n",
    "        return x, x_orig, None\n",
    "\n",
    "    def make_denoise(self, x: torch.Tensor):\n",
    "        if len(x.shape) == 1: x = x.unsqueeze(0)\n",
    "        x_num = x[:, :6]\n",
    "        x_cat = x[:, 6:].long()\n",
    "        x_cat = [emb_layer(x_cat[:, i]) for i, emb_layer in enumerate(self.embeddings)]\n",
    "        x_cat = torch.cat(x_cat, dim=-1)\n",
    "        x = torch.cat([x_num, x_cat], dim=-1).float()\n",
    "        return self.dae_layers(x)\n",
    "\n",
    "    # https://www.kaggle.com/code/ryanzhang/pytorch-dae-starter-code\n",
    "    def add_swapnoise(self, x, ratio=0.15):\n",
    "        obfuscation_mask = torch.bernoulli(ratio * torch.ones(x.shape)).to(DEVICE)\n",
    "        obfuscated_x = torch.where(obfuscation_mask == 1, x[torch.randperm(x.shape[0])], x)\n",
    "        return obfuscated_x, obfuscation_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c62c3ae6-c668-417a-b5fd-0329d59f3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_dae(model, optimizer, loss_fn, train_dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for X, y in tqdm.tqdm(train_dataloader):\n",
    "    # for X, y in train_dataloader:\n",
    "        X = X.to(DEVICE)\n",
    "\n",
    "        preds, orig, mask = model(X)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(preds, orig, mask)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(train_dataloader)\n",
    "    \n",
    "def evaluate_dae(model, loss_fn, test_dataloader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for X, y in test_dataloader:\n",
    "        X = X.to(DEVICE)\n",
    "        \n",
    "        preds, orig, mask = model(X)\n",
    "        loss = loss_fn(preds, orig, mask)\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "263933c4-6549-4774-bf1f-c1847cbce061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE_Weighted(nn.Module):\n",
    "    # when no mask and emphasis = 1 - equvivalent to MSE\n",
    "    def __init__(self, emphasis=1):\n",
    "        self.emphasis = emphasis\n",
    "        # emphasis between 0 and 1\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, actual, mask=None):\n",
    "        if (mask is None): mask = torch.ones(pred.shape).to(DEVICE)\n",
    "        loss_weights = mask * self.emphasis + (1 - mask) * (1 - self.emphasis)\n",
    "        unweighted_loss = nn.functional.mse_loss(pred, actual, reduction='none')\n",
    "        weighted_loss = loss_weights * unweighted_loss\n",
    "        return weighted_loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e4c721-6bbc-42de-a0ba-aa68edffe50d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2224c92-a126-48ad-bbd9-85df38077107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PATH+'pipeline', 'rb') as fp:\n",
    "#     pipeline = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29bf3d24-55d4-4e38-932b-18340b3a6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PATH+'embeddings', 'rb') as fp:\n",
    "#     embeddings = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39b0f4ba-7c48-4140-923e-5716c45877a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18215930"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "958734"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_train_, df_eval_ = train_test_split(df, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                      shuffle=True, stratify=df['Response'].fillna(2)) # without stratify because of  NaNs in test\n",
    "\n",
    "# dataset_train = Base_Dataset(df_train_, is_eval=True) #eval to not to override the pipeline\n",
    "# dataset_eval = Base_Dataset(df_eval_, is_eval=True) #eval to not to override the pipeline\n",
    "\n",
    "# display(len(dataset_train))\n",
    "# display(len(dataset_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f637813-0b3d-4f00-b757-d7458317f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# EMB_0, EMB_1, EMB_2, EMB_3 = 25, 2, 50, 50\n",
    "# INPUT_DIM = 6+EMB_0+EMB_1+EMB_2+EMB_3\n",
    "# LAYERS_NUM = 4\n",
    "# LAYERS_DIM = 1024\n",
    "# # GIST = 128\n",
    "# ACTIVATION = nn.ReLU\n",
    "# EMB_SZS = [(53, EMB_0), (3, EMB_1), (123, EMB_2), (290, EMB_3)]\n",
    "# EMB_WEIGHTS = embeddings\n",
    "# DROPOUT = 0.\n",
    "# SWAPNOISE_RATIO = 0.2\n",
    "\n",
    "# NUM_EPOCHS = 32\n",
    "# BATCH_SIZE = 1024*4 #96\n",
    "# LR = 1e-4 #2e-4 \n",
    "# WEIGHT_DECAY = 5e-5 #6e-5\n",
    "\n",
    "# dae = DAE(input_dim = INPUT_DIM,\n",
    "#               layers_num = LAYERS_NUM,\n",
    "#               layers_dim = LAYERS_DIM,\n",
    "#               # gist_dim = GIST,\n",
    "#               activation = ACTIVATION,\n",
    "#               emb_szs = EMB_SZS,\n",
    "#               emb_weights = EMB_WEIGHTS,\n",
    "#               dropout = DROPOUT,\n",
    "#               swapnoise_ratio = SWAPNOISE_RATIO,\n",
    "#               return_obfuscation_mask=True)\n",
    "# dae.to(DEVICE)\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(dataset_train,\n",
    "#                                           batch_size=BATCH_SIZE, shuffle=True,\n",
    "#                                           num_workers=8, drop_last=False)\n",
    "# evalloader = torch.utils.data.DataLoader(dataset_eval,\n",
    "#                                          batch_size=BATCH_SIZE, shuffle=True,\n",
    "#                                          num_workers=8, drop_last=False)\n",
    "\n",
    "# loss_fn = MSE_Weighted(emphasis=4/5)\n",
    "# # loss_fn = MSE_Weighted(emphasis=1)\n",
    "# # loss_fn = nn.MSELoss()\n",
    "# optimizer = torch.optim.AdamW(dae.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03e7dc52-40e0-42dc-812b-776f65b2bb1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.06353, Val loss: 0.02430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.01864, Val loss: 0.01535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.01380, Val loss: 0.01267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.01191, Val loss: 0.01137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.01086, Val loss: 0.01055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.01020, Val loss: 0.00990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 0.00968, Val loss: 0.00941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 0.00930, Val loss: 0.00919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 0.00900, Val loss: 0.00892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.00878, Val loss: 0.00864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:18<00:00, 56.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.00858, Val loss: 0.00847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 0.00841, Val loss: 0.00836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 0.00828, Val loss: 0.00819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 0.00819, Val loss: 0.00805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 0.00810, Val loss: 0.00806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 0.00802, Val loss: 0.00790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 0.00794, Val loss: 0.00795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 0.00786, Val loss: 0.00785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 0.00782, Val loss: 0.00777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 0.00777, Val loss: 0.00784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train loss: 0.00773, Val loss: 0.00771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train loss: 0.00769, Val loss: 0.00764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train loss: 0.00766, Val loss: 0.00763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train loss: 0.00764, Val loss: 0.00762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train loss: 0.00759, Val loss: 0.00756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train loss: 0.00756, Val loss: 0.00751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train loss: 0.00754, Val loss: 0.00750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train loss: 0.00752, Val loss: 0.00756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train loss: 0.00752, Val loss: 0.00759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:19<00:00, 55.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train loss: 0.00749, Val loss: 0.00743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train loss: 0.00749, Val loss: 0.00740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [01:20<00:00, 55.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train loss: 0.00747, Val loss: 0.00751\n",
      "CPU times: user 1h 4min 7s, sys: 2min 51s, total: 1h 6min 59s\n",
      "Wall time: 44min 43s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     train_loss = train_epoch_dae(dae, optimizer, loss_fn, trainloader)\n",
    "#     eval_loss = evaluate_dae(dae, loss_fn, evalloader)\n",
    "#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.5f}, Val loss: {eval_loss:.5f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bbe99a2-1774-44a9-9e59-f445308e8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dae, 'bottle-dae-model_in-17_ln-2_ld-1024_gist-128_sr-0.2_epch-32_btch-4096_lr-5e4_wd-5e5_unweight.pth')\n",
    "# torch.save(dae, 'bottle-dae-model_in-133_test.pth')\n",
    "# torch.save(dae, 'dae-model_in-133_test.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de12f8-a152-44e8-84a4-4a1d1071c932",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DAE optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8d6dfc6-e9db-4ec2-871b-e761deb9b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_eval = train_test_split(df, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                      shuffle=True, stratify=df['Response'].fillna(2)) #2 for random in NaNs\n",
    "\n",
    "# dataset_train = Base_Dataset(df_train, is_eval=True) #eval to not to override the pipeline\n",
    "# dataset_eval = Base_Dataset(df_eval, is_eval=True) #eval to not to override the pipeline\n",
    "\n",
    "# display(len(dataset_train))\n",
    "# display(len(dataset_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27bc0184-baac-4baa-a49d-646ec5648334",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EMPHASIS = 0.8\n",
    "ACTIVATIONS = {'ReLU': nn.ReLU,\n",
    "               'SELU': nn.SELU,\n",
    "               'GELU': nn.GELU,\n",
    "               'RReLU': nn.RReLU,\n",
    "               'SiLU': nn.SiLU,\n",
    "               'LeakyReLU': nn.LeakyReLU,\n",
    "               'IDENTITY': nn.Identity,\n",
    "              }\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # model's params\n",
    "    INPUT_DIM = 6+25+2+50+50\n",
    "    LAYERS_NUM = trial.suggest_int('LAYERS_NUM', 2, 5, step=1) #4\n",
    "    LAYERS_DIM = trial.suggest_int('LAYERS_DIM', 256, 2048, step=256) #64\n",
    "    ACTIVATION_OPTIONS = trial.suggest_categorical('ACTIVATION', ['ReLU', 'SELU', 'GELU', 'RReLU'])\n",
    "    ACTIVATION = ACTIVATIONS[ACTIVATION_OPTIONS]\n",
    "    EMB_SZS = [(53, 25), (3, 2), (123, 50), (290, 50)]\n",
    "    EMB_WEIGHTS = embeddings\n",
    "    DROPOUT = trial.suggest_float('DROPOUT', 0, 0.2)\n",
    "    \n",
    "    # learning params\n",
    "    NUM_EPOCHS = trial.suggest_int('NUM_EPOCHS', 16, 64, step=8)\n",
    "    BATCH_SIZE = trial.suggest_int('BATCH_SIZE', 1024, 4096, step=1024) #2048\n",
    "    LR = trial.suggest_float('LR', 1e-5, 1e-3, log=True)\n",
    "    WEIGHT_DECAY = trial.suggest_float('WEIGHT_DECAY', 1e-6, 1e-3, log=True)\n",
    "    \n",
    "    dae = DAE(input_dim = INPUT_DIM,\n",
    "              layers_num = LAYERS_NUM,\n",
    "              layers_dim = LAYERS_DIM,\n",
    "              activation = ACTIVATION,\n",
    "              emb_szs = EMB_SZS,\n",
    "              emb_weights = EMB_WEIGHTS,\n",
    "              dropout = DROPOUT,\n",
    "              return_obfuscation_mask=True)\n",
    "    dae.to(DEVICE)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                              batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                              num_workers=4, drop_last=False)\n",
    "    evalloader = torch.utils.data.DataLoader(dataset_eval,\n",
    "                                             batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                             num_workers=4, drop_last=False)\n",
    "    \n",
    "    loss_fn = MSE_Weighted(emphasis=EMPHASIS)\n",
    "    # loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(dae.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        train_loss = train_epoch_dae(dae, optimizer, loss_fn, trainloader)\n",
    "        \n",
    "        if ((epoch)%4==0):\n",
    "            eval_loss = evaluate_dae(dae, loss_fn, evalloader)\n",
    "            trial.report(eval_loss, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    eval_loss = evaluate_dae(dae, loss_fn, evalloader)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e605552-bcef-47a9-a0d2-91f592846686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampler = optuna.samplers.TPESampler(seed=42)\n",
    "# # storage = optuna.storages.InMemoryStorage()\n",
    "\n",
    "# study = optuna.create_study(direction='minimize', sampler=sampler,\n",
    "#                             study_name='dae-study_mse0', storage='sqlite:///dae-study_mse.db', load_if_exists=True,\n",
    "#                             pruner=optuna.pruners.MedianPruner(n_startup_trials=16,\n",
    "#                                                                n_warmup_steps=16) #8\n",
    "#                            )\n",
    "# study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5158409-fb67-450b-9e93-68fce44cb3ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Сompresser training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df9f72-b49d-4749-a882-fd443d15a4d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Сompresser Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6860bf28-50b6-4fca-8546-256548062180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dae_model,\n",
    "                 dae_out_dim: int = 1024*4,\n",
    "                 layers_num: int = 2,\n",
    "                 layers_dim: int = 32,\n",
    "                 activation = nn.ReLU,\n",
    "                 dropout: float = 0.,\n",
    "                 feature_dim = 256,\n",
    "                ):\n",
    "        super(FCHead, self).__init__()\n",
    "\n",
    "        for p in dae_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        fc_layers = []\n",
    "        fc_layers.append(nn.Linear(dae_out_dim, dae_out_dim//4))\n",
    "        fc_layers.append(nn.LazyBatchNorm1d())\n",
    "        fc_layers.append(activation())\n",
    "        fc_layers.append(nn.Dropout(p=dropout))\n",
    "        fc_layers.append(nn.Linear(dae_out_dim//4, feature_dim))\n",
    "        fc_layers.append(nn.LazyBatchNorm1d())\n",
    "        fc_layers.append(activation())\n",
    "        fc_layers.append(nn.Dropout(p=dropout))\n",
    "        fc_layers.append(nn.Linear(feature_dim, 1))\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(*fc_layers)\n",
    "        self.feature_extractor = nn.Sequential(*list(self.fc_layers.children())[0:5])\n",
    "\n",
    "        # self.fc_layers = nn.Sequential(nn.Linear(dae_out_dim, dae_out_dim),\n",
    "        #                                nn.LazyBatchNorm1d(),\n",
    "        #                                activation(),\n",
    "        #                                nn.Linear(dae_out_dim, dae_out_dim),\n",
    "        #                                nn.LazyBatchNorm1d(),\n",
    "        #                                activation(),\n",
    "        #                                nn.Linear(dae_out_dim, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = dae.make_denoise(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "    def feature_maker(self, x: torch.Tensor):\n",
    "        x = dae.make_denoise(x)\n",
    "        x = self.feature_extractor(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749263d8-8352-40b4-a794-caf23e864d9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Сompresser Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dad76802-59eb-41c3-b18f-5a784421f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dae = torch.load('dae_model.pth')\n",
    "# dae = torch.load('bottle-dae-model_ln-2_ld-1024_sr-0.2_epch-64_btch-2048_lr-7e5_wd-2e5_unweight.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d19ec3e-bec9-470b-af7d-5d957cb52ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_train, df_train_eval = train_test_split(df_train, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                                  shuffle=True, stratify=df_train[target])\n",
    "\n",
    "# dataset_train = Base_Dataset(df_train_train, is_eval=True)\n",
    "# dataset_eval = Base_Dataset(df_train_eval, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d26c368-58ca-4eb9-a483-911009cad669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gin/anaconda3/envs/env0/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ACTIVATION = nn.SELU\n",
    "# DAE_OUT_DIM = 1024*4 #128 #1024*4\n",
    "# FEATURE_DIM = 1024\n",
    "# DROPOUT = 0.1\n",
    "\n",
    "# NUM_EPOCHS = 16\n",
    "# BATCH_SIZE = 1024*4 #96\n",
    "# LR = 0.001\n",
    "# WEIGHT_DECAY = 0.001 #5e-4\n",
    "\n",
    "# compresser = FCHead(dae_model=dae,\n",
    "#                     dae_out_dim = DAE_OUT_DIM,\n",
    "#                     activation=ACTIVATION,\n",
    "#                     dropout=DROPOUT,\n",
    "#                     feature_dim=FEATURE_DIM,\n",
    "#                     )\n",
    "\n",
    "# altmetric_train = MetricCollection([AUROC(task='binary'),\n",
    "#                                     Recall(task='binary'),\n",
    "#                                     Precision(task='binary'),\n",
    "#                                     F1Score(task='binary'),\n",
    "#                                     Accuracy(task='binary')\n",
    "#                                    ])\n",
    "# altmetric_eval = MetricCollection([AUROC(task='binary'),\n",
    "#                                    Recall(task='binary'),\n",
    "#                                    Precision(task='binary'),\n",
    "#                                    F1Score(task='binary'),\n",
    "#                                    Accuracy(task='binary')\n",
    "#                                   ])\n",
    "\n",
    "# compresser.to(DEVICE)\n",
    "# altmetric_train.to(DEVICE)\n",
    "# altmetric_eval.to(DEVICE)\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(dataset_train,\n",
    "#                                           batch_size=BATCH_SIZE, shuffle=True,\n",
    "#                                           num_workers=8, drop_last=False)\n",
    "# evalloader = torch.utils.data.DataLoader(dataset_eval,\n",
    "#                                          batch_size=BATCH_SIZE, shuffle=True,\n",
    "#                                          num_workers=8, drop_last=False)\n",
    "\n",
    "# loss_fn = nn.BCEWithLogitsLoss(\n",
    "#                                # weight=torch.Tensor([8]).to(DEVICE),\n",
    "#                                # pos_weight=torch.Tensor([8]).to(DEVICE)\n",
    "#                               )\n",
    "# optimizer = torch.optim.AdamW(compresser.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8fb8f45-b86e-4105-8ecc-70971b4c7229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.25105, Val loss: 0.25159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.25097, Val loss: 0.25165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.25092, Val loss: 0.25153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.25089, Val loss: 0.25156\n",
      "Train\n",
      "('BinaryAUROC', 0.88083)\n",
      "('BinaryRecall', 0.13293)\n",
      "('BinaryPrecision', 0.56902)\n",
      "('BinaryF1Score', 0.21551)\n",
      "('BinaryAccuracy', 0.88097)\n",
      "\n",
      "Test\n",
      "('BinaryAUROC', 0.87979)\n",
      "('BinaryRecall', 0.12503)\n",
      "('BinaryPrecision', 0.56251)\n",
      "('BinaryF1Score', 0.20458)\n",
      "('BinaryAccuracy', 0.88042)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.25085, Val loss: 0.25146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.25085, Val loss: 0.25157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 0.25081, Val loss: 0.25157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 0.25079, Val loss: 0.25157\n",
      "Train\n",
      "('BinaryAUROC', 0.88096)\n",
      "('BinaryRecall', 0.13386)\n",
      "('BinaryPrecision', 0.56962)\n",
      "('BinaryF1Score', 0.21677)\n",
      "('BinaryAccuracy', 0.88103)\n",
      "\n",
      "Test\n",
      "('BinaryAUROC', 0.87976)\n",
      "('BinaryRecall', 0.12439)\n",
      "('BinaryPrecision', 0.56269)\n",
      "('BinaryF1Score', 0.20374)\n",
      "('BinaryAccuracy', 0.88041)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 0.25077, Val loss: 0.25159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.25075, Val loss: 0.25159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.25074, Val loss: 0.25163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 0.25073, Val loss: 0.25166\n",
      "Train\n",
      "('BinaryAUROC', 0.88105)\n",
      "('BinaryRecall', 0.13397)\n",
      "('BinaryPrecision', 0.56931)\n",
      "('BinaryF1Score', 0.2169)\n",
      "('BinaryAccuracy', 0.88101)\n",
      "\n",
      "Test\n",
      "('BinaryAUROC', 0.87975)\n",
      "('BinaryRecall', 0.13598)\n",
      "('BinaryPrecision', 0.55696)\n",
      "('BinaryF1Score', 0.21859)\n",
      "('BinaryAccuracy', 0.88042)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:42<00:00, 63.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 0.25070, Val loss: 0.25159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 0.25068, Val loss: 0.25158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 64.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 0.25067, Val loss: 0.25158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2669/2669 [00:41<00:00, 63.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 0.25068, Val loss: 0.25171\n",
      "Train\n",
      "('BinaryAUROC', 0.88114)\n",
      "('BinaryRecall', 0.13494)\n",
      "('BinaryPrecision', 0.57056)\n",
      "('BinaryF1Score', 0.21825)\n",
      "('BinaryAccuracy', 0.88111)\n",
      "\n",
      "Test\n",
      "('BinaryAUROC', 0.87969)\n",
      "('BinaryRecall', 0.13003)\n",
      "('BinaryPrecision', 0.55849)\n",
      "('BinaryF1Score', 0.21095)\n",
      "('BinaryAccuracy', 0.88035)\n",
      "\n",
      "CPU times: user 10min 14s, sys: 56 s, total: 11min 10s\n",
      "Wall time: 11min 45s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# PRINT_EVERY = 4\n",
    "\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     train_loss = train_epoch_fcnn(compresser, optimizer, loss_fn, trainloader, altmetric=altmetric_train)\n",
    "#     eval_loss = evaluate_fcnn(compresser, loss_fn, evalloader, altmetric=altmetric_eval)\n",
    "#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.5f}, Val loss: {eval_loss:.5f}\"))\n",
    "\n",
    "#     if ((epoch)%PRINT_EVERY==0):\n",
    "#         print('Train')\n",
    "#         for j in [(i, round(altmetric_train[i].compute().item(), 5))\n",
    "#                   for i in altmetric_train.keys()]: print(j)\n",
    "#         print()\n",
    "#         print('Test')\n",
    "#         for j in [(i, round(altmetric_eval[i].compute().item(), 5))\n",
    "#                   for i in altmetric_eval.keys()]: print(j)\n",
    "#         print()\n",
    "\n",
    "#     altmetric_train.reset()\n",
    "#     altmetric_eval.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "672e9e36-dec5-46a0-8cf8-5640dc39c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(compresser, 'compresser_model-128.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61eec01-ba65-435a-a0c3-a7a9209728e3",
   "metadata": {},
   "source": [
    "### GBM HEAD training (from Compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8749ac-8656-4521-b37e-eaa384e4c247",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### LGBM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "927d18f4-a191-4564-9c16-dcbfbc5211d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoised_Compressed_Dataset():\n",
    "    def __init__(self, df, compresser,\n",
    "                 is_eval=False, is_test=False):\n",
    "        \n",
    "        self.df = df\n",
    "        # self.dae_model = dae_model\n",
    "        # self.dae_model.to(DEVICE)\n",
    "        # self.dae_model.eval()\n",
    "        # for p in dae_model.parameters():\n",
    "        #     p.requires_grad = False\n",
    "        self.compresser = compresser\n",
    "        self.compresser.to(DEVICE)\n",
    "        self.compresser.eval()\n",
    "        for p in compresser.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.is_eval = is_eval\n",
    "        self.is_test = is_test\n",
    "        self.dataset = Base_Dataset(df, is_eval=self.is_eval, is_test=self.is_test)\n",
    "        gc.collect()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index]\n",
    "        X, y = torch.Tensor(X).to(DEVICE),\\\n",
    "               torch.Tensor(y).to(DEVICE)\n",
    "        X = compresser.feature_maker(X)\n",
    "        X, y = X.detach().cpu().numpy(), y.detach().cpu().numpy()\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95775c-7233-4181-b83a-b3bd710c3e32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### LGBM HEAD Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c35a848-8a4e-4354-9066-08287f078c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_train_train, df_train_eval = train_test_split(df_train, test_size=EVAL_SIZE, random_state=SEED,\n",
    "# #                                                  shuffle=True, stratify=df_train[target])\n",
    "\n",
    "# # dataset_train = Denoised_Compressed_Dataset(df_train_train, compresser=compresser, is_eval=True)\n",
    "# # dataset_eval = Denoised_Compressed_Dataset(df_train_eval, compresser=compresser, is_eval=True)\n",
    "# dataset_train = Denoised_Compressed_Dataset(df_train, compresser=compresser, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6f1466e-cb5d-4fb6-b043-ad0d88d52771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 1024*4\n",
    "\n",
    "# X_train, y_train = [], []\n",
    "# batches = (-(-len(dataset_train)//BATCH_SIZE))\n",
    "# index_start = 0\n",
    "# index_end = BATCH_SIZE\n",
    "\n",
    "# for batch in range(0, batches):\n",
    "#     X, y = dataset_train[index_start:index_end]\n",
    "#     X_train.append(X)\n",
    "#     y_train.append(y)\n",
    "#     index_start = index_end\n",
    "#     index_end += BATCH_SIZE\n",
    "\n",
    "# # X_eval, y_eval = [], []\n",
    "# # batches = (-(-len(dataset_eval)//BATCH_SIZE))\n",
    "# # index_start = 0\n",
    "# # index_end = BATCH_SIZE\n",
    "\n",
    "# # for batch in range(0, batches):\n",
    "# #     X, y = dataset_eval[index_start:index_end]\n",
    "# #     X_eval.append(X)\n",
    "# #     y_eval.append(y)\n",
    "# #     index_start = index_end\n",
    "# #     index_end += BATCH_SIZE\n",
    "\n",
    "# X_train, y_train = np.concatenate(X_train, axis=0), np.concatenate(y_train, axis=0)\n",
    "# y_train = y_train.reshape(-1)\n",
    "\n",
    "# # X_eval, y_eval = np.concatenate(X_eval, axis=0), np.concatenate(y_eval, axis=0)\n",
    "# # y_eval = y_eval.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cde02b08-d60c-4b3d-865d-0f6a43825a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 μs, sys: 1e+03 ns, total: 4 μs\n",
      "Wall time: 7.87 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# np.save('X_train.npy', X_train)\n",
    "# np.save('y_train.npy', y_train)\n",
    "# X_train = np.load('X_train.npy')\n",
    "# y_train = np.load('y_train.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a5820-85eb-4ac2-bbb8-c3747ba2f628",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### LGBM HEAD Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1c5c702-be80-4759-becd-6590c4d71286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f799201f-e30c-49e0-a72a-ce4cd11dcd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dataset_train\n",
    "# del dataset_eval\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4636389e-404e-4cc1-b0ee-d43baae78446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # gbm = XGBClassifier(n_esimators=300, eval_metric='roc_auc', verbose=0, scale_pos_weight=5, device='cuda')\n",
    "# # gbm = CatBoostClassifier(iterations=128, devices='cuda')\n",
    "# gbm = LGBMClassifier(device='gpu')\n",
    "# # gbm.fit(X_train, y_train)\n",
    "# cv_results = cross_validate(gbm, X_train, y_train, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08269256-3142-4537-88a9-76b25ead0ccc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### LGBM HEAD optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ffe3b637-dea8-4bc8-b907-907892da28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "\n",
    "#     params = {\n",
    "#         'objective': 'binary',\n",
    "#         'boosting': 'gbdt', #trial.suggest_categorical('boosting', ['gbdt', 'dart']),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 16, 64, step=4)-1,\n",
    "#         'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'data', 'voting']),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 8, 64, step=8),\n",
    "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 4, 32, step=4),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 10, log=True),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 10, log=True),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1, log=True),\n",
    "#         'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 8),\n",
    "#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1, log=True),\n",
    "#         'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1, log=True),\n",
    "#         # 'max_bin': trial.suggest_int('max_bin', 64, 512, step=64)-1,\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 128, 1024, step=128),\n",
    "#         # 'n_jobs': 8,\n",
    "#         'device': 'gpu',\n",
    "#         'random_state': SEED,\n",
    "#         'verbose': 0,\n",
    "#         # 'force_col_wise':True,\n",
    "#         # 'force_row_wise':True,\n",
    "#     }\n",
    "\n",
    "#     gbm = LGBMClassifier(**params)\n",
    "#     cv_results = cross_validate(gbm, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "#     gc.collect()\n",
    "    \n",
    "#     return cv_results['test_score'].mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5285a63-367b-4ec4-a48d-233d1b856927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler=sampler,\n",
    "#                             study_name='lgbm-study_auc0', storage='sqlite:///lgbm-study_auc.db', load_if_exists=True,\n",
    "#                            )\n",
    "# study.optimize(objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2ae5d-9e4d-44a5-a5b4-e14acdf65a98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GBM HEAD training (from DAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235fe7f-bab3-4027-9347-1de070010572",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GBM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19b709a9-3d22-417f-9074-c40e59f85db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dae = torch.load('bottle-dae-model_in-133_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f7d7127-27b7-4f9b-9838-1c089aa6a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoised_Dataset():\n",
    "    def __init__(self, df, dae_model,\n",
    "                 is_eval=False, is_test=False,\n",
    "                 dtype='float32'):\n",
    "        \n",
    "        self.df = df\n",
    "        self.is_eval = is_eval\n",
    "        self.is_test = is_test\n",
    "        self.dataset = Base_Dataset(df, is_eval=self.is_eval, is_test=self.is_test)\n",
    "        self.dae_model = dae_model\n",
    "        self.dae_model.to(DEVICE)\n",
    "        self.dae_model.eval()\n",
    "        for p in self.dae_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.dtype = dtype\n",
    "        gc.collect()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index]\n",
    "        X, y = torch.Tensor(X).to(DEVICE),\\\n",
    "               torch.Tensor(y).to(DEVICE)\n",
    "        X = dae.make_denoise(X)\n",
    "        X, y = X.detach().cpu().numpy(),\\\n",
    "               y.detach().cpu().numpy()\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b0115-49f6-4fbb-89ea-200753d37f7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GBM HEAD Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9680fb6-3ea2-4aa1-85dc-167e90c62a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_train, df_train_eval = train_test_split(df_train, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                                  shuffle=True, stratify=df_train[target])\n",
    "\n",
    "# dataset_train = Denoised_Dataset(df_train_train, dae_model=dae, is_eval=True)\n",
    "# dataset_eval = Denoised_Dataset(df_train_eval, dae_model=dae, is_eval=True)\n",
    "# dataset_full = Denoised_Dataset(df_train, dae_model=dae, is_eval=True, dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29679d3e-7eed-48e3-8c05-bfc2b4feb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 1024*4\n",
    "\n",
    "# X_train, y_train = [], []\n",
    "# batches = (-(-len(dataset_train)//BATCH_SIZE))\n",
    "# index_start = 0\n",
    "# index_end = BATCH_SIZE\n",
    "\n",
    "# for batch in range(0, batches):\n",
    "#     X, y = dataset_train[index_start:index_end]\n",
    "#     X_train.append(X)\n",
    "#     y_train.append(y)\n",
    "#     index_start = index_end\n",
    "#     index_end += BATCH_SIZE\n",
    "\n",
    "# X_eval, y_eval = [], []\n",
    "# batches = (-(-len(dataset_eval)//BATCH_SIZE))\n",
    "# index_start = 0\n",
    "# index_end = BATCH_SIZE\n",
    "\n",
    "# for batch in range(0, batches):\n",
    "#     X, y = dataset_eval[index_start:index_end]\n",
    "#     X_eval.append(X)\n",
    "#     y_eval.append(y)\n",
    "#     index_start = index_end\n",
    "#     index_end += BATCH_SIZE\n",
    "\n",
    "# X_train, y_train = np.concatenate(X_train, axis=0), np.concatenate(y_train, axis=0)\n",
    "# y_train = y_train.reshape(-1)\n",
    "\n",
    "# X_eval, y_eval = np.concatenate(X_eval, axis=0), np.concatenate(y_eval, axis=0)\n",
    "# y_eval = y_eval.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9aa82998-3ba5-4663-a437-5ee40dad7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 1024*4\n",
    "\n",
    "# X_, y_ = [], []\n",
    "# batches = (-(-len(dataset_full)//BATCH_SIZE))\n",
    "# index_start = 0\n",
    "# index_end = BATCH_SIZE\n",
    "\n",
    "# for batch in range(0, batches):\n",
    "#     X, y = dataset_full[index_start:index_end]\n",
    "#     X_.append(X)\n",
    "#     y_.append(y)\n",
    "#     index_start = index_end\n",
    "#     index_end += BATCH_SIZE\n",
    "\n",
    "# X_, y_ = np.concatenate(X_, axis=0), np.concatenate(y_, axis=0)\n",
    "# y_ = y_.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce1e5893-1fc9-45b3-b07c-9ef5607e4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# name = '256_float32.npy'\n",
    "\n",
    "# # np.save('X_train_'+name, X_train)\n",
    "# # np.save('y_train_'+name, y_train)\n",
    "# # np.save('X_eval_'+name, X_eval)\n",
    "# # np.save('y_eval_'+name, y_eval)\n",
    "\n",
    "# X_train = np.load('X_train_'+name)\n",
    "# y_train = np.load('y_train_'+name)\n",
    "# X_eval = np.load('X_eval_'+name)\n",
    "# y_eval = np.load('y_eval_'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb6abd-70e2-423a-8090-9cdae6942f66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GBM HEAD Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "455e1a4c-6562-4d43-8a88-f4719515270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5073118a-59e0-4073-95e3-0403560d5dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1344306, number of negative: 9585252\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 32640\n",
      "[LightGBM] [Info] Number of data points in the train set: 10929558, number of used features: 128\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 128 dense feature groups (1334.17 MB) transferred to GPU in 0.765896 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "CPU times: user 21min, sys: 9.29 s, total: 21min 10s\n",
      "Wall time: 3min 21s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.3, n_estimators=1024, verbose=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(device=&#x27;gpu&#x27;, learning_rate=0.3, n_estimators=1024, verbose=500)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(device='gpu', learning_rate=0.3, n_estimators=1024, verbose=500)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# gbm = XGBClassifier(n_esimators=2000,\n",
    "#                     max_depth=16,\n",
    "#                     # early_stopping_rounds=50,\n",
    "#                     # eval_metric='auc',\n",
    "#                     device='cuda')\n",
    "# gbm = CatBoostClassifier(loss_function='Logloss',\n",
    "#                          eval_metric='AUC',\n",
    "#                          # learning_rate=0.03,\n",
    "#                          # depth=4,\n",
    "#                          iterations=1024,\n",
    "#                          early_stopping_rounds=50,\n",
    "#                          # random_strength=0,\n",
    "#                          # max_leaves=512,\n",
    "#                          # fold_permutation_block=64,                         \n",
    "#                          task_type='GPU')\n",
    "\n",
    "# gbm = LGBMClassifier(n_estimators=1024,\n",
    "#                      verbose=500,\n",
    "#                      learning_rate=0.3,\n",
    "#                      # max_depth=8,\n",
    "#                      device='gpu')\n",
    "# gbm.fit(X_train, y_train, eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "# gbm.fit(X_train, y_train,\n",
    "#         eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "# cv_results = cross_validate(gbm, X_train, y_train, eval_set=[X_eval, y_eval], scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c76fe88b-243b-406a-bf60-b500d3984f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8724192420189854"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc_auc_score(y_eval, gbm.predict_proba(X_eval)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b245338-eab8-4a11-bc71-ea615a090fad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GBM HEAD optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd9fbfd8-0d97-42c4-bab2-5fdf976f78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # params = {\n",
    "    #     'objective': 'binary',\n",
    "    #     'boosting': 'gbdt', #trial.suggest_categorical('boosting', ['gbdt', 'dart']),\n",
    "    #     'num_leaves': trial.suggest_int('num_leaves', 16, 64, step=4)-1,\n",
    "    #     'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'data', 'voting']),\n",
    "    #     'max_depth': trial.suggest_int('max_depth', 4, 64, step=4),\n",
    "    #     'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 4, 32, step=4),\n",
    "    #     'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 10, log=True),\n",
    "    #     'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 10, log=True),\n",
    "    #     'learning_rate': trial.suggest_float('learning_rate', 1e-2, 0.5, log=True),\n",
    "    #     'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1/4, 8, log=True),\n",
    "    #     'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1, log=True),\n",
    "    #     'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1, log=True),\n",
    "    #     # 'max_bin': trial.suggest_int('max_bin', 64, 512, step=64)-1,\n",
    "    #     'n_estimators': trial.suggest_int('n_estimators', 128, 2048, step=128),\n",
    "    #     # 'n_jobs': 8,\n",
    "    #     'device': 'gpu',\n",
    "    #     'random_state': SEED,\n",
    "    #     'verbose': 0,\n",
    "    #     # 'force_col_wise':True,\n",
    "    #     # 'force_row_wise':True,\n",
    "    # }\n",
    "\n",
    "    params = {\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.5, log=True),\n",
    "        'random_seed': SEED,\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.001, 10, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.01, 10, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 16, step=1),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 31, step=5),\n",
    "        # 'max_leaves': trial.suggest_int('max_leaves', 16, 64, step=10)-1,\n",
    "        'scale_pos_weight': trial.suggest_int('scale_pos_weight', 1/4, 8, step=1),\n",
    "        'task_type': 'GPU',\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "\n",
    "    # gbm = LGBMClassifier(**params)\n",
    "    gbm = CatBoostClassifier(**params)\n",
    "    gbm.fit(X_train, y_train, eval_set=[(X_eval, y_eval)])\n",
    "    eval_metric = roc_auc_score(y_eval, gbm.predict_proba(X_eval)[:, 1])\n",
    "    # cv_results = cross_validate(gbm, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "    gc.collect()\n",
    "    \n",
    "    # return cv_results['test_score'].mean()\n",
    "    return eval_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e564b458-d4c8-4048-8f02-e0520ffe13ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 20:46:02,388] A new study created in RDB with name: cgbm-study_auc0\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 20:48:30,958] Trial 0 finished with value: 0.8656141091836125 and parameters: {'learning_rate': 0.17962832718526836, 'l2_leaf_reg': 0.00891589366282252, 'bagging_temperature': 2.970541321550833, 'depth': 16, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'scale_pos_weight': 5}. Best is trial 0 with value: 0.8656141091836125.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 20:49:47,782] Trial 1 finished with value: 0.8724092635264595 and parameters: {'learning_rate': 0.13899733172806242, 'l2_leaf_reg': 0.0013808487031636222, 'bagging_temperature': 0.0785865842510549, 'depth': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'scale_pos_weight': 3}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 20:51:29,723] Trial 2 finished with value: 0.8464745129388984 and parameters: {'learning_rate': 0.005221503151912826, 'l2_leaf_reg': 0.027122838050872754, 'bagging_temperature': 7.0352987629863435, 'depth': 6, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'scale_pos_weight': 5}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 20:52:14,257] Trial 3 finished with value: 0.8670385585187836 and parameters: {'learning_rate': 0.27963845300695234, 'l2_leaf_reg': 0.0010835848620837983, 'bagging_temperature': 1.736727619400401, 'depth': 14, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'scale_pos_weight': 8}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 20:54:03,132] Trial 4 finished with value: 0.8562630442823554 and parameters: {'learning_rate': 0.005000277090854771, 'l2_leaf_reg': 0.009725564175863451, 'bagging_temperature': 1.3699289192285382, 'depth': 8, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 6, 'scale_pos_weight': 4}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 20:54:26,981] Trial 5 finished with value: 0.5273614140082726 and parameters: {'learning_rate': 0.016030806425710437, 'l2_leaf_reg': 0.03291040038634612, 'bagging_temperature': 0.6510532120605528, 'depth': 14, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'scale_pos_weight': 0}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 20:59:56,298] Trial 6 finished with value: 0.8697005241093657 and parameters: {'learning_rate': 0.015491312503852394, 'l2_leaf_reg': 0.004047125298822383, 'bagging_temperature': 5.997682040604332, 'depth': 12, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'scale_pos_weight': 7}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:00:15,158] Trial 7 finished with value: 0.5094279955732771 and parameters: {'learning_rate': 0.032330244553774416, 'l2_leaf_reg': 0.0037973791033993768, 'bagging_temperature': 0.037390405576119855, 'depth': 10, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'scale_pos_weight': 0}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:01:18,867] Trial 8 finished with value: 0.8718227734482757 and parameters: {'learning_rate': 0.33527071321744845, 'l2_leaf_reg': 0.028818000432808622, 'bagging_temperature': 0.04783696637794113, 'depth': 15, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 16, 'scale_pos_weight': 8}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:03:06,544] Trial 9 finished with value: 0.8723524170178398 and parameters: {'learning_rate': 0.04031332973478747, 'l2_leaf_reg': 0.0032796862442608043, 'bagging_temperature': 1.9129474080810385, 'depth': 6, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 31, 'scale_pos_weight': 1}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:04:21,707] Trial 10 finished with value: 0.8711036030974572 and parameters: {'learning_rate': 0.10010490527231077, 'l2_leaf_reg': 1.02586125007047, 'bagging_temperature': 0.13681326414870454, 'depth': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 11, 'scale_pos_weight': 3}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:05:40,784] Trial 11 finished with value: 0.8699452552310497 and parameters: {'learning_rate': 0.07898709255488132, 'l2_leaf_reg': 0.21105305003177194, 'bagging_temperature': 0.010479600469333187, 'depth': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 31, 'scale_pos_weight': 2}. Best is trial 1 with value: 0.8724092635264595.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:07:36,093] Trial 12 finished with value: 0.8725729573859826 and parameters: {'learning_rate': 0.048005127491660034, 'l2_leaf_reg': 0.0015721514682771956, 'bagging_temperature': 0.26601668906290554, 'depth': 7, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'scale_pos_weight': 2}. Best is trial 12 with value: 0.8725729573859826.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:09:22,439] Trial 13 finished with value: 0.8749400905894686 and parameters: {'learning_rate': 0.13165109603935965, 'l2_leaf_reg': 5.8702009322856945, 'bagging_temperature': 0.19823134571846077, 'depth': 7, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'scale_pos_weight': 2}. Best is trial 13 with value: 0.8749400905894686.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:11:48,281] Trial 14 finished with value: 0.8750020635103817 and parameters: {'learning_rate': 0.06518693963392808, 'l2_leaf_reg': 9.6839117709739, 'bagging_temperature': 0.3101188311064988, 'depth': 9, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'scale_pos_weight': 2}. Best is trial 14 with value: 0.8750020635103817.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:12:54,082] Trial 15 finished with value: 0.8719975984880612 and parameters: {'learning_rate': 0.44752715495846657, 'l2_leaf_reg': 9.261512226299146, 'bagging_temperature': 0.3999614312886764, 'depth': 10, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'scale_pos_weight': 2}. Best is trial 14 with value: 0.8750020635103817.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:15:26,117] Trial 16 finished with value: 0.8752304043420216 and parameters: {'learning_rate': 0.08020093705611647, 'l2_leaf_reg': 9.377159212257116, 'bagging_temperature': 0.21007442326612583, 'depth': 9, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 1}. Best is trial 16 with value: 0.8752304043420216.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:19:34,033] Trial 17 finished with value: 0.8740257199498725 and parameters: {'learning_rate': 0.024971711306665985, 'l2_leaf_reg': 1.968239923189068, 'bagging_temperature': 0.6611701448660942, 'depth': 12, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 1}. Best is trial 16 with value: 0.8752304043420216.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:21:10,505] Trial 18 finished with value: 0.8746891053159471 and parameters: {'learning_rate': 0.07236872901752679, 'l2_leaf_reg': 0.6141771832200774, 'bagging_temperature': 0.030057206972602835, 'depth': 9, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 21, 'scale_pos_weight': 1}. Best is trial 16 with value: 0.8752304043420216.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:24:48,835] Trial 19 finished with value: 0.8750949607173817 and parameters: {'learning_rate': 0.06265308089360568, 'l2_leaf_reg': 3.640690201720811, 'bagging_temperature': 0.10941820682497962, 'depth': 12, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 4}. Best is trial 16 with value: 0.8752304043420216.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:29:02,592] Trial 20 finished with value: 0.8741440282426319 and parameters: {'learning_rate': 0.022072005785605392, 'l2_leaf_reg': 3.533758358794342, 'bagging_temperature': 0.10272444946447577, 'depth': 12, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 5}. Best is trial 16 with value: 0.8752304043420216.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:32:20,722] Trial 21 finished with value: 0.8753397816161379 and parameters: {'learning_rate': 0.06255850287715824, 'l2_leaf_reg': 2.581381568131091, 'bagging_temperature': 0.35690095243548187, 'depth': 11, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 4}. Best is trial 21 with value: 0.8753397816161379.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:33:58,538] Trial 22 finished with value: 0.873261158751286 and parameters: {'learning_rate': 0.19100956126948127, 'l2_leaf_reg': 0.43727813880212835, 'bagging_temperature': 0.5243613451035121, 'depth': 11, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 6}. Best is trial 21 with value: 0.8753397816161379.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:37:14,881] Trial 23 finished with value: 0.8753538517943259 and parameters: {'learning_rate': 0.05474377322899502, 'l2_leaf_reg': 2.2039135565124517, 'bagging_temperature': 0.15784316475118831, 'depth': 11, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 16, 'scale_pos_weight': 4}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:40:02,093] Trial 24 finished with value: 0.8741112733251424 and parameters: {'learning_rate': 0.03639095075809461, 'l2_leaf_reg': 1.8188726878969876, 'bagging_temperature': 0.9029848406470561, 'depth': 10, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 11, 'scale_pos_weight': 4}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:41:35,412] Trial 25 finished with value: 0.8748602291001768 and parameters: {'learning_rate': 0.10395586281665008, 'l2_leaf_reg': 0.1644520930477088, 'bagging_temperature': 0.1658888971703723, 'depth': 13, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 11, 'scale_pos_weight': 3}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:45:08,778] Trial 26 finished with value: 0.8698310458660725 and parameters: {'learning_rate': 0.010947702919542491, 'l2_leaf_reg': 1.5376139916835927, 'bagging_temperature': 0.01797695961434776, 'depth': 11, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 16, 'scale_pos_weight': 6}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:47:25,864] Trial 27 finished with value: 0.8747081254480455 and parameters: {'learning_rate': 0.05356937922272236, 'l2_leaf_reg': 4.509904411666684, 'bagging_temperature': 0.06515439224445103, 'depth': 9, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 11, 'scale_pos_weight': 6}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:49:24,605] Trial 28 finished with value: 0.8747996825827106 and parameters: {'learning_rate': 0.09628439586632966, 'l2_leaf_reg': 0.5162702202685314, 'bagging_temperature': 0.2703153750972117, 'depth': 11, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 4}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:51:20,414] Trial 29 finished with value: 0.8675630755920063 and parameters: {'learning_rate': 0.2320657120258285, 'l2_leaf_reg': 2.5097944788534474, 'bagging_temperature': 2.982797170333134, 'depth': 16, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 16, 'scale_pos_weight': 5}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:52:23,429] Trial 30 finished with value: 0.8742343391583526 and parameters: {'learning_rate': 0.15554597302962972, 'l2_leaf_reg': 0.9295912972341467, 'bagging_temperature': 0.9925787657043121, 'depth': 13, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 31, 'scale_pos_weight': 3}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:55:31,582] Trial 31 finished with value: 0.8748109811161761 and parameters: {'learning_rate': 0.06199929842788592, 'l2_leaf_reg': 5.533876326571609, 'bagging_temperature': 0.12168630562692782, 'depth': 13, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 4}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:58:01,618] Trial 32 finished with value: 0.8752549430675158 and parameters: {'learning_rate': 0.04864551968044725, 'l2_leaf_reg': 2.7522505067700247, 'bagging_temperature': 0.08499705922646675, 'depth': 11, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 4}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 21:59:37,067] Trial 33 finished with value: 0.8713370375207197 and parameters: {'learning_rate': 0.028084019268228417, 'l2_leaf_reg': 1.1382016491558862, 'bagging_temperature': 0.07848579523734941, 'depth': 8, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 16, 'scale_pos_weight': 5}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:01:42,673] Trial 34 finished with value: 0.8750237644595329 and parameters: {'learning_rate': 0.04872606816827099, 'l2_leaf_reg': 0.3051925455712271, 'bagging_temperature': 0.201834883124361, 'depth': 10, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'scale_pos_weight': 3}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:03:36,609] Trial 35 finished with value: 0.8747086957124554 and parameters: {'learning_rate': 0.08609108807033125, 'l2_leaf_reg': 0.06738321059651244, 'bagging_temperature': 0.0510615575884688, 'depth': 11, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 16, 'scale_pos_weight': 7}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:05:11,590] Trial 36 finished with value: 0.8753403305744272 and parameters: {'learning_rate': 0.12710518162573525, 'l2_leaf_reg': 2.747722345696908, 'bagging_temperature': 0.4295295323302192, 'depth': 8, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 4}. Best is trial 23 with value: 0.8753538517943259.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:06:46,335] Trial 37 finished with value: 0.8753744665235526 and parameters: {'learning_rate': 0.13512242180149386, 'l2_leaf_reg': 2.601162347104033, 'bagging_temperature': 0.39497262686028617, 'depth': 8, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'scale_pos_weight': 4}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:07:41,558] Trial 38 finished with value: 0.87409183654002 and parameters: {'learning_rate': 0.12616182002296855, 'l2_leaf_reg': 0.8057653526902454, 'bagging_temperature': 0.39139052065149393, 'depth': 8, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'scale_pos_weight': 5}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:08:35,066] Trial 39 finished with value: 0.8739229007444849 and parameters: {'learning_rate': 0.23880248271065804, 'l2_leaf_reg': 0.11536641279441001, 'bagging_temperature': 0.4427343302890176, 'depth': 6, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 1, 'scale_pos_weight': 3}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:09:42,049] Trial 40 finished with value: 0.8739186717807284 and parameters: {'learning_rate': 0.1806719743271747, 'l2_leaf_reg': 1.339180548262957, 'bagging_temperature': 0.7985271704108429, 'depth': 7, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'scale_pos_weight': 4}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:11:11,545] Trial 41 finished with value: 0.8748733219563897 and parameters: {'learning_rate': 0.11561208725034441, 'l2_leaf_reg': 3.3022403827597118, 'bagging_temperature': 1.334390365425077, 'depth': 8, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 4}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:13:13,908] Trial 42 finished with value: 0.8744881809788955 and parameters: {'learning_rate': 0.038837775817889636, 'l2_leaf_reg': 2.214523900164019, 'bagging_temperature': 0.5095534301453644, 'depth': 10, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 11, 'scale_pos_weight': 5}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:14:17,680] Trial 43 finished with value: 0.8735312244892273 and parameters: {'learning_rate': 0.15218205176764002, 'l2_leaf_reg': 0.012713734412769124, 'bagging_temperature': 0.2980308651897528, 'depth': 11, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'scale_pos_weight': 4}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:20:33,556] Trial 44 finished with value: 0.8744190144196935 and parameters: {'learning_rate': 0.018807443990770098, 'l2_leaf_reg': 6.498799762303011, 'bagging_temperature': 0.1560093021956875, 'depth': 14, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 16, 'scale_pos_weight': 4}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:21:37,548] Trial 45 finished with value: 0.8499800381583855 and parameters: {'learning_rate': 0.007567491084966264, 'l2_leaf_reg': 2.884874002061245, 'bagging_temperature': 0.09609566968213802, 'depth': 5, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 1, 'scale_pos_weight': 3}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:23:19,056] Trial 46 finished with value: 0.872654203268823 and parameters: {'learning_rate': 0.04555280256643708, 'l2_leaf_reg': 1.4495761660985573, 'bagging_temperature': 2.9395212314354224, 'depth': 9, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'scale_pos_weight': 5}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:23:43,896] Trial 47 finished with value: 0.8707675623198928 and parameters: {'learning_rate': 0.31343599838249936, 'l2_leaf_reg': 0.2980444409312366, 'bagging_temperature': 0.025809291378813177, 'depth': 8, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 16, 'scale_pos_weight': 6}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:25:04,021] Trial 48 finished with value: 0.8706487017209399 and parameters: {'learning_rate': 0.03212506562599902, 'l2_leaf_reg': 5.816145389231329, 'bagging_temperature': 0.06173145337932973, 'depth': 7, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 26, 'scale_pos_weight': 3}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:28:26,811] Trial 49 finished with value: 0.8719836595925567 and parameters: {'learning_rate': 0.06066529374822745, 'l2_leaf_reg': 2.390923472539797, 'bagging_temperature': 9.371217797528526, 'depth': 12, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 5}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[I 2024-07-24 22:29:29,479] Trial 50 finished with value: 0.8723053884704235 and parameters: {'learning_rate': 0.09030365134087721, 'l2_leaf_reg': 0.7530366954385932, 'bagging_temperature': 0.6461442079841045, 'depth': 5, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 11, 'scale_pos_weight': 4}. Best is trial 37 with value: 0.8753744665235526.\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "[W 2024-07-24 22:29:42,102] Trial 51 failed with parameters: {'learning_rate': 0.07699316580529862, 'l2_leaf_reg': 9.705336153431585, 'bagging_temperature': 0.20184768660269928, 'depth': 9, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 21, 'scale_pos_weight': 0} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gin/anaconda3/envs/env0/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1140235/781599914.py\", line 45, in objective\n",
      "    gbm.fit(X_train, y_train, eval_set=[(X_eval, y_eval)])\n",
      "  File \"/home/gin/anaconda3/envs/env0/lib/python3.11/site-packages/catboost/core.py\", line 5220, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/home/gin/anaconda3/envs/env0/lib/python3.11/site-packages/catboost/core.py\", line 2400, in _fit\n",
      "    self._train(\n",
      "  File \"/home/gin/anaconda3/envs/env0/lib/python3.11/site-packages/catboost/core.py\", line 1780, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4833, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4882, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2024-07-24 22:29:42,114] Trial 51 failed with value None.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler=sampler,\n",
    "#                             study_name='cgbm-study_auc0', storage='sqlite:///lgbm-study_auc.db', load_if_exists=True,\n",
    "#                            )\n",
    "# study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7e3e5-ef71-4f63-8c03-440451e001ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GBM HEAD training (from CosEmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082cd35f-6acf-4561-a7b5-d80386ec6ebd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GBM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30ba048-7051-4e6c-a1f3-371dfb4b40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder = torch.load('cosemb256-wnum-128.pth')\n",
    "\n",
    "# with open(PATH+'pipeline', 'rb') as fp:\n",
    "#     pipeline = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5274a167-d7a0-432d-8647-5330951aa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedded_Dataset():\n",
    "    def __init__(self, df, embedder,\n",
    "                 is_eval=False, is_test=False,\n",
    "                 dtype='float32'):\n",
    "        \n",
    "        self.df = df\n",
    "        self.is_eval = is_eval\n",
    "        self.is_test = is_test\n",
    "        self.dataset = Base_Dataset(df, is_eval=self.is_eval, is_test=self.is_test)\n",
    "        self.embedder = embedder\n",
    "        self.embedder.to(DEVICE)\n",
    "        self.embedder.eval()\n",
    "        for p in self.embedder.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.dtype = dtype\n",
    "        gc.collect()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index]\n",
    "        X, y = torch.Tensor(X).to(DEVICE),\\\n",
    "               torch.Tensor(y).to(DEVICE)\n",
    "        X = embedder.make_embs(X)\n",
    "        X, y = X.detach().cpu().numpy(),\\\n",
    "               y.detach().cpu().numpy()\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca4f0f-f66f-439b-9409-022ca70d11f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GBM HEAD Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33efdb1-d399-4c13-bf97-64ba72b1ca4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0482cc1e-e3c4-4922-81a2-486f149ccf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_train, df_train_eval = train_test_split(df_train, test_size=EVAL_SIZE, random_state=SEED,\n",
    "#                                                  shuffle=True, stratify=df_train[target])\n",
    "\n",
    "# dataset_train = Embedded_Dataset(df_train_train, embedder=embedder, is_eval=True)\n",
    "# dataset_eval = Embedded_Dataset(df_train_eval, embedder=embedder, is_eval=True)\n",
    "# dataset_full = Denoised_Dataset(df_train, dae_model=dae, is_eval=True, dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c63292c7-89ec-4af8-a8e9-f8728773ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 1024*4\n",
    "\n",
    "# X_train, y_train = [], []\n",
    "# batches = (-(-len(dataset_train)//BATCH_SIZE))\n",
    "# index_start = 0\n",
    "# index_end = BATCH_SIZE\n",
    "\n",
    "# for batch in range(0, batches):\n",
    "#     X, y = dataset_train[index_start:index_end]\n",
    "#     X_train.append(X)\n",
    "#     y_train.append(y)\n",
    "#     index_start = index_end\n",
    "#     index_end += BATCH_SIZE\n",
    "\n",
    "# X_eval, y_eval = [], []\n",
    "# batches = (-(-len(dataset_eval)//BATCH_SIZE))\n",
    "# index_start = 0\n",
    "# index_end = BATCH_SIZE\n",
    "\n",
    "# for batch in range(0, batches):\n",
    "#     X, y = dataset_eval[index_start:index_end]\n",
    "#     X_eval.append(X)\n",
    "#     y_eval.append(y)\n",
    "#     index_start = index_end\n",
    "#     index_end += BATCH_SIZE\n",
    "\n",
    "# X_train, y_train = np.concatenate(X_train, axis=0), np.concatenate(y_train, axis=0)\n",
    "# y_train = y_train.reshape(-1)\n",
    "\n",
    "# X_eval, y_eval = np.concatenate(X_eval, axis=0), np.concatenate(y_eval, axis=0)\n",
    "# y_eval = y_eval.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e57d1873-ebea-40cd-a81c-2e1fb8610ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 1024*4\n",
    "\n",
    "# X_, y_ = [], []\n",
    "# batches = (-(-len(dataset_full)//BATCH_SIZE))\n",
    "# index_start = 0\n",
    "# index_end = BATCH_SIZE\n",
    "\n",
    "# for batch in range(0, batches):\n",
    "#     X, y = dataset_full[index_start:index_end]\n",
    "#     X_.append(X)\n",
    "#     y_.append(y)\n",
    "#     index_start = index_end\n",
    "#     index_end += BATCH_SIZE\n",
    "\n",
    "# X_, y_ = np.concatenate(X_, axis=0), np.concatenate(y_, axis=0)\n",
    "# y_ = y_.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e304468-734f-4e05-8e76-28b55ba10199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# name = '256_float32.npy'\n",
    "\n",
    "# # np.save('X_train_'+name, X_train)\n",
    "# # np.save('y_train_'+name, y_train)\n",
    "# # np.save('X_eval_'+name, X_eval)\n",
    "# # np.save('y_eval_'+name, y_eval)\n",
    "\n",
    "# X_train = np.load('X_train_'+name)\n",
    "# y_train = np.load('y_train_'+name)\n",
    "# X_eval = np.load('X_eval_'+name)\n",
    "# y_eval = np.load('y_eval_'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79eabf9-5bfe-4239-a8e4-6978c957e6cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GBM HEAD Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58541a36-0192-4e55-a14a-8701afbd4799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# gbm = XGBClassifier(n_esimators=1024,\n",
    "#                     max_depth=9,\n",
    "#                     # early_stopping_rounds=50,\n",
    "#                     eval_metric='auc',\n",
    "#                     device='cuda')\n",
    "# # gbm = CatBoostClassifier(loss_function='Logloss',\n",
    "# #                          eval_metric='AUC',\n",
    "# #                          # learning_rate=0.03,\n",
    "# #                          # depth=4,\n",
    "# #                          iterations=2048,\n",
    "# #                          early_stopping_rounds=50,\n",
    "# #                          # random_strength=0,\n",
    "# #                          # max_leaves=512,\n",
    "# #                          # fold_permutation_block=64,                         \n",
    "# #                          task_type='GPU')\n",
    "\n",
    "# # gbm = LGBMClassifier(n_estimators=1024,\n",
    "# #                      verbose=500,\n",
    "# #                      # learning_rate=0.2,\n",
    "# #                      # max_depth=8,\n",
    "# #                      device='gpu')\n",
    "# gbm.fit(X_train, y_train, eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "# # gbm.fit(X_train, y_train,\n",
    "# #         eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "# # cv_results = cross_validate(gbm, X_train, y_train, eval_set=[X_eval, y_eval], scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05409ab5-0762-49e9-8887-533a4c61505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8712647421976389"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc_auc_score(y_eval, gbm.predict_proba(X_eval)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8150f54-5d8d-44aa-8570-94143f529245",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### GBM HEAD optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c53fd73-2407-4bd9-8802-428e96e0b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # params = {\n",
    "    #     'objective': 'binary',\n",
    "    #     'boosting': 'gbdt', #trial.suggest_categorical('boosting', ['gbdt', 'dart']),\n",
    "    #     'num_leaves': trial.suggest_int('num_leaves', 16, 64, step=4)-1,\n",
    "    #     'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'data', 'voting']),\n",
    "    #     'max_depth': trial.suggest_int('max_depth', 4, 64, step=4),\n",
    "    #     'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 4, 32, step=4),\n",
    "    #     'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 10, log=True),\n",
    "    #     'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 10, log=True),\n",
    "    #     'learning_rate': trial.suggest_float('learning_rate', 1e-2, 0.5, log=True),\n",
    "    #     'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1/4, 8, log=True),\n",
    "    #     'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1, log=True),\n",
    "    #     'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1, log=True),\n",
    "    #     # 'max_bin': trial.suggest_int('max_bin', 64, 512, step=64)-1,\n",
    "    #     'n_estimators': trial.suggest_int('n_estimators', 128, 2048, step=128),\n",
    "    #     # 'n_jobs': 8,\n",
    "    #     'device': 'gpu',\n",
    "    #     'random_state': SEED,\n",
    "    #     'verbose': 0,\n",
    "    #     # 'force_col_wise':True,\n",
    "    #     # 'force_row_wise':True,\n",
    "    # }\n",
    "\n",
    "    params = {\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.5, log=True),\n",
    "        'random_seed': SEED,\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.001, 10, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.01, 10, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 16, step=1),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 31, step=5),\n",
    "        # 'max_leaves': trial.suggest_int('max_leaves', 16, 64, step=10)-1,\n",
    "        'scale_pos_weight': trial.suggest_int('scale_pos_weight', 1/4, 8, step=1),\n",
    "        'task_type': 'GPU',\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "\n",
    "    # gbm = LGBMClassifier(**params)\n",
    "    gbm = CatBoostClassifier(**params)\n",
    "    gbm.fit(X_train, y_train, eval_set=[(X_eval, y_eval)])\n",
    "    eval_metric = roc_auc_score(y_eval, gbm.predict_proba(X_eval)[:, 1])\n",
    "    # cv_results = cross_validate(gbm, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "    gc.collect()\n",
    "    \n",
    "    # return cv_results['test_score'].mean()\n",
    "    return eval_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b47935d-0069-40f2-aa2f-0ac42276b6e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampler = optuna.samplers.TPESampler(seed=SEED)\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler=sampler,\n",
    "#                             study_name='cgbm-study_auc0', storage='sqlite:///lgbm-study_auc.db', load_if_exists=True,\n",
    "#                            )\n",
    "# study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13929f8-96c7-4f56-806e-2fea0df8f3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
